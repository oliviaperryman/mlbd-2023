{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04- Extended Exercises on Classification and Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "jp4ln17R8BNF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel, mutual_info_classif\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data directory\n",
    "DATA_DIR = \"./../../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnSVIV4Xu_wt",
    "tags": []
   },
   "source": [
    "You are the Senior Data Scientist in a learning platform called LernTime. You have realized that many users stop using the platform and want to increase user retention. For this purpose, you decide to build a model to predict whether a student will stop using the learning platform or not.\n",
    "\n",
    "Your data science team built a data frame in which each row contains the aggregated features per student (calculated over the first 5 weeks of interactions) and the feature `dropout` indicates whether the student stopped using the platform (1) or not (0) before week 10.\n",
    "\n",
    "The dataframe is in the file `lerntime.csv` and contains the following features:\n",
    "- `video_time`: total video time (in minutes) \n",
    "- `num_sessions` total number of sessions\n",
    "- `num_quizzes`: total number of quizzes attempts\n",
    "- `reading_time`: total theory reading time\n",
    "- `previous_knowledge`: standardized previous knowledge\n",
    "- `browser_speed`: standardized browser speed\n",
    "- `device`:  whether the student logged in using a smartphone (1) or a computer (-1)\n",
    "- `topics`: the topics covered by the user\n",
    "- `education`: current level of education (0: middle school, 1: high school, 2: bachelor, 3: master, 4: Ph.D.).\n",
    "- `dropout`: whether the student stopped using the platform (1) or not (0) before week 5.\n",
    "\n",
    "The newest data scientist created two models with an excellent performance. As a Senior Data Scientist, you are suspicious of the results and decide to revise the code. \n",
    "\n",
    "Your task is to:\n",
    "\n",
    "a) Identify the mistakes. In the first cell, add a comment above each line in which you identify an error and explain the error.\n",
    "\n",
    "b) In the second cell, you must correct the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your name:  Paola\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lab-04',\n",
    "    'session_owner': 'mlbd',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TtWJ4sDNvXQP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('{DATA_DIR}lerntime_dropout.csv')\n",
    "\n",
    "y = df['dropout']\n",
    "X = df[['video_time', 'num_sessions', 'num_quizzes', 'reading_time',\n",
    "       'previous_knowledge', 'browser_speed']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r85IEfMeCgq9"
   },
   "source": [
    "### Task A) Identify the mistakes in the code \n",
    "In the following cell, add a comment above each line in which you identify an error and explain the why it is erroneous.\n",
    "Please start each of your comments with `#ERROR:`. For example:\n",
    "\n",
    "`#ERROR: the RMSE of the model is printed instead of the AUC`\n",
    "\n",
    "`print(\"The AUC of the model is: {}\".format(rmse))          `\n",
    "\n",
    "You may assume that: \n",
    "- all the features are continous and numerical. \n",
    "- the features have already been cleaned and processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Or-X9lyFFVAm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n",
      "(300, 3)\n",
      "Score model 1: 0.05\n",
      "Score model 2: 1.0\n"
     ]
    }
   ],
   "source": [
    "## 1. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## 2. Feature selection (Lasso)\n",
    "print(X.shape)\n",
    "lasso = Lasso(alpha=0.1, random_state=0).fit(X, y)\n",
    "selector = SelectFromModel(lasso, prefit = True)\n",
    "X = selector.transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "## 3. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "## Model 1\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=1, random_state=0)\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Score model 1: {}\".format(np.round(adjusted_mutual_info_score(preds, y_test), 2)))\n",
    "\n",
    "## Model 2\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, random_state=0)\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Score model 2: {}\".format(np.round(adjusted_mutual_info_score(preds, y_test), 2)))\n",
    "\n",
    "\n",
    "## Discussion\n",
    "# Our second model achieved perfect results with unseen data and outperforms the first model.\n",
    "## This is because we increased the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = \"\"\"\n",
    "COPY THE ERRORS IDENTIFIED HERE\n",
    "\"\"\"\n",
    "\n",
    "send(answer, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acDnbzGiCnBD"
   },
   "source": [
    "### Task B) Correct the code \n",
    "Correct all the erroneous code in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "7wkyo3yACcb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 3)\n",
      "(240, 3)\n",
      "Score model 1: 0.9\n",
      "Score model 2: 0.81\n"
     ]
    }
   ],
   "source": [
    "## 1. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## 2. Feature selection (Lasso)\n",
    "print(X.shape)\n",
    "lasso = Lasso(alpha=0.1, random_state=0).fit(X, y)\n",
    "selector = SelectFromModel(lasso, prefit = True)\n",
    "X = selector.transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "## 3. Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "\n",
    "## Model 1\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=1, random_state=0)\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Score model 1: {}\".format(np.round(adjusted_mutual_info_score(preds, y_test), 2)))\n",
    "\n",
    "## Model 2\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, random_state=0)\n",
    "clf.fit(X,y)\n",
    "preds = clf.predict(X_test)\n",
    "print(\"Score model 2: {}\".format(np.round(adjusted_mutual_info_score(preds, y_test), 2)))\n",
    "\n",
    "\n",
    "## Discussion\n",
    "# Our second model achieved perfect results with unseen data and outperforms the first model.\n",
    "## This is because we increased the number of estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"\n",
    "COPY OUTPUT OF MODEL SCORE HERE\n",
    "\"\"\"\n",
    "\n",
    "send(answer, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C) Re-write your code using pipelines.\n",
    "Hint: Go over sklearn-pipeline-introduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"\n",
    "WRITE THE BEST PARAMETERS AND SCORE HERE\n",
    "\"\"\"\n",
    "\n",
    "send(answer, 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = \"\"\"\n",
    "DO THE RESULTS DIFFER, WHY? \n",
    "\"\"\"\n",
    "\n",
    "send(answer, 4) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "clean_exam_coding_questions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
