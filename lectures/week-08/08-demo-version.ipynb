{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49ae0f85-f44e-483a-a97e-d29271e12115",
   "metadata": {
    "id": "49ae0f85-f44e-483a-a97e-d29271e12115"
   },
   "source": [
    "# Lecture 8 - Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64e078-e002-483e-b74d-d22a3fc95260",
   "metadata": {
    "id": "9c64e078-e002-483e-b74d-d22a3fc95260"
   },
   "source": [
    "Recurrent neural networks can handle time series data of different lengths. In this demo notebook we will first look deeper into Deep Knowledge Tracing, before showing examples of different types of neural network models for tracing and time series tasks. The learning objectives of this notebook are as follows:\n",
    "\n",
    "1. Explore the differences between deep learning architectures for time-series data with LSTMs, GRUs and RNNs.\n",
    "\n",
    "2. Implement hyperparameter tuning for a deep learning pipeline.\n",
    "\n",
    "3. Contrast two behavioral time-series data settings: a model that makes a prediction at every time interval vs. a model that makes an overall prediction at the end of the time series.\n",
    "\n",
    "If you are using EPFL's Noto, this notebook will need to use the `Tensorflow` kernel for the dependencies to be installed appropriately. Change the kernel in the upper right corner of Noto. Select `Tensorflow`.  \n",
    "\n",
    "Note that the model training and hyperparameter search cells will take a very long time to run on Noto. We recommend using Google Colab for this notebook if you would like to run the cells from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46040b51-cf1f-4029-a2a6-2bf7c94ee04e",
   "metadata": {
    "id": "46040b51-cf1f-4029-a2a6-2bf7c94ee04e"
   },
   "outputs": [],
   "source": [
    "# Load standard imports for the rest of the notebook.\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import tensorflow as tf\n",
    "\n",
    "# In this demo, we use a lot of SciKit-Learn functions, as imported below.\n",
    "from sklearn import feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "DATA_DIR = \"./../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "173b722b-20ec-4ff5-8d07-821b0ad3eb2c",
   "metadata": {
    "id": "173b722b-20ec-4ff5-8d07-821b0ad3eb2c"
   },
   "outputs": [],
   "source": [
    "def create_iterator(data):\n",
    "    '''\n",
    "    Create an iterator to split interactions in data into train and test, with the same student not appearing in two diverse folds.\n",
    "    :param data:        Dataframe with student's interactions.\n",
    "    :return:            An iterator.\n",
    "    '''    \n",
    "    # Both passing a matrix with the raw data or just an array of indexes works\n",
    "    X = np.arange(len(data.index))\n",
    "    # Groups of interactions are identified by the user id (we do not want the same user appearing in two folds)\n",
    "    groups = data['user_id'].values \n",
    "    return model_selection.GroupShuffleSplit(n_splits=1, train_size=.8, test_size=0.2, random_state=0).split(X, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea03ccc-da16-4b98-b6b4-b2dd4decdce3",
   "metadata": {
    "id": "2ea03ccc-da16-4b98-b6b4-b2dd4decdce3",
    "tags": []
   },
   "source": [
    "## Deep Knowledge Tracing (DKT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7509d1-0a9c-45f7-9fa2-7954e6013644",
   "metadata": {
    "id": "2a7509d1-0a9c-45f7-9fa2-7954e6013644"
   },
   "source": [
    "We begin by loading the data of the ASSISTments dataset (that we have explored in previous lectures). \n",
    "\n",
    "The ASSISTments data sets are often used for benchmarking knowledge tracing models. We will play with a simplified data set that contains the following columns:\n",
    "\n",
    "| Name                   | Description                         |\n",
    "| ---------------------- | ------------------------------------------------------------ |\n",
    "| user_id | The ID of the student who is solving the problem.  | |\n",
    "| order_id | The temporal ID (timestamp) associated with the student's answer to the problem.  | |\n",
    "| skill_name | The name of the skill associated with the problem. | |\n",
    "| correct | The student's performance on the problem: 1 if the problem's answer is correct at the first attempt, 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b61453-4bb2-4f39-acc0-b63b7c4e11e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "a4b61453-4bb2-4f39-acc0-b63b7c4e11e2",
    "outputId": "f8035dda-2263-4986-ab97-d3fbfe9d427c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-90154ec3-9be3-49a9-a2e7-2b1f9e2818ce\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_id</th>\n",
       "      <th>skill_name</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022537</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64525</td>\n",
       "      <td>33022709</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70363</td>\n",
       "      <td>35450204</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70363</td>\n",
       "      <td>35450295</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70363</td>\n",
       "      <td>35450311</td>\n",
       "      <td>Box and Whisker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90154ec3-9be3-49a9-a2e7-2b1f9e2818ce')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-90154ec3-9be3-49a9-a2e7-2b1f9e2818ce button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-90154ec3-9be3-49a9-a2e7-2b1f9e2818ce');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  order_id       skill_name  correct\n",
       "0    64525  33022537  Box and Whisker        1\n",
       "1    64525  33022709  Box and Whisker        1\n",
       "2    70363  35450204  Box and Whisker        0\n",
       "3    70363  35450295  Box and Whisker        1\n",
       "4    70363  35450311  Box and Whisker        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DATA_DIR + 'assistments.csv', low_memory=False).dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5d4b6-08d3-486d-8a48-474f5419c6d2",
   "metadata": {
    "id": "7eb5d4b6-08d3-486d-8a48-474f5419c6d2"
   },
   "source": [
    "Next, we print the number of students and skills in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e14881-5cd4-4a50-b98c-fa0fa5a92626",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5e14881-5cd4-4a50-b98c-fa0fa5a92626",
    "outputId": "eeacebde-90ee-4a76-9e87-ffc9fcd922c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique students in the dataset: 4151\n",
      "Number of unique skills in the dataset: 110\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique students in the dataset:\", len(set(data['user_id'])))\n",
    "print(\"Number of unique skills in the dataset:\", len(set(data['skill_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KMG2F0_b5F6P",
   "metadata": {
    "id": "KMG2F0_b5F6P"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03374938-2408-42e8-a39a-130b049c9614",
   "metadata": {
    "id": "03374938-2408-42e8-a39a-130b049c9614"
   },
   "source": [
    "Since the data needs to be fed into the model in batches, we need to specify in advance how many elements per batch the DKT model will receive. DKT also requires that all sequences need to be of the same length in order to be used as model input. \n",
    "\n",
    "Given that students have different number of opportunities across skills, we need to define a scheme such that the sequences will be the same length. We choose to pad our values to the maximum sequence length and determine a masking value (for the model to ignore) for those entries that are introduced as a padding into the student's sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cPQYLdJ91Pgd",
   "metadata": {
    "id": "cPQYLdJ91Pgd"
   },
   "outputs": [],
   "source": [
    "def prepare_seq(df):\n",
    "    '''\n",
    "    Extract user_id sequence in preparation for DKT. The output of this function \n",
    "    feeds into the prepare_data() function. \n",
    "    '''\n",
    "    # Enumerate skill id as a categorical variable \n",
    "    # (i.e. [32, 12, 32, 45] -> [0, 1, 0, 2])\n",
    "    df['skill'], skill_codes = pd.factorize(df['skill_name'], sort=True)\n",
    "\n",
    "    # Cross skill id with answer to form a synthetic feature\n",
    "    df['skill_with_answer'] = df['skill'] * 2 + df['correct']\n",
    "\n",
    "    # Convert to a sequence per user_id and shift features 1 timestep\n",
    "    seq = df.groupby('user_id').apply(lambda r: (r['skill_with_answer'].values[:-1], r['skill'].values[1:], r['correct'].values[1:],))\n",
    "    \n",
    "    # Get max skill depth and max feature depth\n",
    "    skill_depth = df['skill'].max() \n",
    "    features_depth = df['skill_with_answer'].max() + 1\n",
    "\n",
    "    return seq, features_depth, skill_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "U-hvy9zC1Q42",
   "metadata": {
    "id": "U-hvy9zC1Q42"
   },
   "outputs": [],
   "source": [
    "def prepare_data(seq, params, features_depth, skill_depth):\n",
    "    '''\n",
    "    Manipulate the data sequences into the right format for DKT with padding by batch\n",
    "    and encoding categorical features.\n",
    "    '''\n",
    "    \n",
    "    # Get Tensorflow Dataset\n",
    "    dataset = tf.data.Dataset.from_generator(generator=lambda: seq, output_types=(tf.int32, tf.int32, tf.float32))\n",
    "\n",
    "    # Encode categorical features and merge skills with labels to compute target loss\n",
    "    dataset = dataset.map(\n",
    "        lambda feat, skill, label: (\n",
    "            tf.one_hot(feat, depth=features_depth),\n",
    "            tf.concat(values=[tf.one_hot(skill, depth=skill_depth), tf.expand_dims(label, -1)], axis=-1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Pad sequences to the appropriate length per batch\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size=params['batch_size'],\n",
    "        padding_values=(params['mask_value'], params['mask_value']),\n",
    "        padded_shapes=([None, None], [None, None]),\n",
    "        drop_remainder=True\n",
    "    )\n",
    "\n",
    "    return dataset.repeat(), len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "xdlT_vrl2hc0",
   "metadata": {
    "id": "xdlT_vrl2hc0"
   },
   "outputs": [],
   "source": [
    "# Specify the model hyperparameters\n",
    "params = {}\n",
    "\n",
    "# The 'batch_size' parameter refers to the number of instances the model evaluates\n",
    "# at a time. We choose the 'batch_size' based on the size of our dataset, the diversity\n",
    "# of our data instances, and the size of each instance. Most times, people use batches\n",
    "# in the binary family tree {8, 16, 32, 64, 128, 256}. If your batch size is large, your\n",
    "# model trains faster, but if your batch size is small, each instance is more valued in \n",
    "# the model training process. It's a tradeoff between computational efficiency and \n",
    "# instance importance.\n",
    "params['batch_size'] = 32\n",
    "\n",
    "# The parameter 'mask_value' tells our model which input values to ignore. None of \n",
    "# our features will have the value -1.0 naturally, so it's a good choice to use for \n",
    "# marking (or 'masking') invalid values so the model does not consider them. We will\n",
    "# use this parameter in our padding case, since we don't want our model to consider the\n",
    "# extra values we're including in our sequences to make them the same length in each batch.\n",
    "params['mask_value'] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc0dd7-e714-4086-b55d-ee2111573d57",
   "metadata": {
    "id": "4cbc0dd7-e714-4086-b55d-ee2111573d57"
   },
   "source": [
    "We then split the data into a train, a validation and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc81f84e-ec62-4442-95d5-58a24f428c28",
   "metadata": {
    "id": "cc81f84e-ec62-4442-95d5-58a24f428c28"
   },
   "outputs": [],
   "source": [
    "# Obtain indexes for training and test sets\n",
    "train_index, test_index = next(create_iterator(data))\n",
    "\n",
    "# Split the data into training and test\n",
    "X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "# Obtain indexes for training and validation sets\n",
    "train_val_index, val_index = next(create_iterator(X_train))\n",
    "\n",
    "# Split the training data into training and validation\n",
    "X_train_val, X_val = X_train.iloc[train_val_index], X_train.iloc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "EsLMWu6G2sIk",
   "metadata": {
    "id": "EsLMWu6G2sIk"
   },
   "outputs": [],
   "source": [
    "# Build TensorFlow sequence datasets for training, validation, and test data\n",
    "seq, features_depth, skill_depth = prepare_seq(data)\n",
    "seq_train = seq[X_train_val.user_id.unique()]\n",
    "seq_val = seq[X_val.user_id.unique()]\n",
    "seq_test = seq[X_test.user_id.unique()]\n",
    "\n",
    "# Prepare the training, validation, and test data in the DKT input format\n",
    "tf_train, length = prepare_data(seq_train, params, features_depth, skill_depth)\n",
    "tf_val, val_length  = prepare_data(seq_val, params, features_depth, skill_depth)\n",
    "tf_test, test_length = prepare_data(seq_test, params, features_depth, skill_depth)\n",
    "\n",
    "# Calculate the length of each of the train-test-val sets and store as parameters\n",
    "params['train_size'] = int(length // params['batch_size'])\n",
    "params['val_size'] = int(val_length // params['batch_size'])\n",
    "params['test_size'] = int(test_length // params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xV_6sL3j5JqO",
   "metadata": {
    "id": "xV_6sL3j5JqO"
   },
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504b631-a4f5-45b9-8e4f-37203b1e84b2",
   "metadata": {
    "id": "c504b631-a4f5-45b9-8e4f-37203b1e84b2"
   },
   "source": [
    "First, we train DKT using an LSTM architecture and default parameter settings. We use a validation set to monitor prediction accuracy of the model and store the model with the best weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f8922b-397c-4501-8e27-d5eed77b746c",
   "metadata": {
    "id": "a4f8922b-397c-4501-8e27-d5eed77b746c"
   },
   "outputs": [],
   "source": [
    "# The 'verbose' parameter can be set to {0, 1, 2} to specify the level of logging we want from \n",
    "# the model during training. 1 is usually a good compromise between being inundated with info\n",
    "# and not knowing what's going on in your model (i.e. loss, epochs, metric).\n",
    "params['verbose'] = 1\n",
    "\n",
    "# As we train the model, we want to continually save only the best model iteration.\n",
    "# The 'best_model_weights' parameter tells our training code where to save the model.\n",
    "params['best_model_weights'] = 'weights/bestmodel' \n",
    "\n",
    "# The 'optimizer' parameter specifies which gradient descent optimizer to use in backpropogation. \n",
    "# 'adam' is a common choice. Others include 'SGD', 'RMSProp', or 'ADAgrad', among many others.\n",
    "params['optimizer'] = 'adam'\n",
    "\n",
    "# The 'recurrent_units' parameter refers to the of hidden units in your recurrent layer. \n",
    "# This is a very common hyperparameter to tune as it usually makes a substantial difference \n",
    "# in model performance (as we'll see later on).\n",
    "params['recurrent_units'] = 16\n",
    "\n",
    "# How long do we want our model to train? Each time the model sees all the data in the training \n",
    "# process is an 'epoch'. If the model trains for too long (sees the data too many times), it'll \n",
    "# overfit; although we don't have to worry about this because we're only saving the best model \n",
    "# (see: best_model_weights). If it trains for not long enough, it'll underfit. There's also a \n",
    "# tradeoff between quality of model and amount of computational resources / time. For now, 20's \n",
    "# a good number. As a rule of thumb, 100 epochs is usually a lot, and 10 epochs is usually too \n",
    "# little, but it depends on the diversity of your data and what you're trying to predict.\n",
    "params['epochs'] = 20\n",
    "\n",
    "# A really interesting research discovery in 2013 found that neural nets perform better when \n",
    "# they forget a portion of their weights and replace them with 0s. This is the notion of dropout.\n",
    "# The 'dropout_rate' parameter tells our model what fraction of weights to throw away or 'drop out' \n",
    "# each epoch. Want to read the paper? https://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf\n",
    "params['dropout_rate'] = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44168260-1ff8-47d7-9476-c1bf6fd9ffe7",
   "metadata": {
    "id": "44168260-1ff8-47d7-9476-c1bf6fd9ffe7"
   },
   "source": [
    "Considering that we padded the sequences such that all have the same length, we need to remove predictions for the time steps that are based on padded data. To this end, we implement a function called get_target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae15693f-2019-4838-a656-67e3f191e6c3",
   "metadata": {
    "id": "ae15693f-2019-4838-a656-67e3f191e6c3"
   },
   "outputs": [],
   "source": [
    "def get_target(y_true, y_pred, mask_value=params['mask_value']):\n",
    "    ''' \n",
    "    Adjust y_true and y_pred to ignore predictions made using padded values.\n",
    "    '''\n",
    "    # Get skills and labels from y_true\n",
    "    mask = 1. - tf.cast(tf.equal(y_true, mask_value), y_true.dtype)\n",
    "    y_true = y_true * mask\n",
    "\n",
    "    skills, y_true = tf.split(y_true, num_or_size_splits=[-1, 1], axis=-1)\n",
    "\n",
    "    # Get predictions for each skill\n",
    "    y_pred = tf.reduce_sum(y_pred * skills, axis=-1, keepdims=True)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc0eb8-4dfc-411e-a53f-fa0d3d836aaf",
   "metadata": {
    "id": "88cc0eb8-4dfc-411e-a53f-fa0d3d836aaf"
   },
   "source": [
    "While training and evaluating the model, we will monitor the following performance metrics. Please, note that we need to process our targets before using the default TensorFlow metric functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f38f90b9-82f5-42eb-b732-027551086674",
   "metadata": {
    "id": "f38f90b9-82f5-42eb-b732-027551086674"
   },
   "outputs": [],
   "source": [
    "class AUC(tf.keras.metrics.AUC):\n",
    "    # Our custom AUC calls our get_target function first to remove predictions on padded values, \n",
    "    # then computes a standard AUC metric.\n",
    "    def __init__(self):\n",
    "        # We use a super constructor here just to make our metric name pretty!\n",
    "        super(AUC, self).__init__(name='auc')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true, pred = get_target(y_true, y_pred)\n",
    "        super(AUC, self).update_state(y_true=true, y_pred=pred, sample_weight=sample_weight)\n",
    "\n",
    "class RMSE(tf.keras.metrics.RootMeanSquaredError):\n",
    "    # Our custom RMSE calls our get_target function first to remove predictions on padded values, \n",
    "    # then computes a standard RMSE metric.\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true, pred = get_target(y_true, y_pred)\n",
    "        super(RMSE, self).update_state(y_true=true, y_pred=pred, sample_weight=sample_weight)\n",
    "        \n",
    "def CustomBinaryCrossEntropy(y_true, y_pred): \n",
    "    # Our custom binary cross entropy loss calls our get_target function first \n",
    "    # to remove predictions on padded values, then computes standard binary cross-entropy.\n",
    "    y_true, y_pred = get_target(y_true, y_pred)\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73112110-b257-49f1-a443-0746658714e9",
   "metadata": {
    "id": "73112110-b257-49f1-a443-0746658714e9"
   },
   "source": [
    "We define an LSTM and a GRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce3ed83-1c11-479c-9467-2d6894c49c22",
   "metadata": {
    "id": "5ce3ed83-1c11-479c-9467-2d6894c49c22"
   },
   "outputs": [],
   "source": [
    "def create_model_lstm(nb_features, nb_skills, params):\n",
    "    \n",
    "    # Create an LSTM model architecture\n",
    "    inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
    "\n",
    "    # We use a masking layer here to ignore our masked padding values\n",
    "    x = tf.keras.layers.Masking(mask_value=params['mask_value'])(inputs)\n",
    "\n",
    "    # This LSTM layer is the crux of the model; we use our parameters to specify\n",
    "    # what this layer should look like (# of recurrent_units, fraction of dropout).\n",
    "    x = tf.keras.layers.LSTM(params['recurrent_units'], return_sequences=True, dropout=params['dropout_rate'])(x)\n",
    "    \n",
    "    # We use a dense layer with the sigmoid function activation to map our predictions \n",
    "    # between 0 and 1.\n",
    "    dense = tf.keras.layers.Dense(nb_skills, activation='sigmoid')\n",
    "\n",
    "    # The TimeDistributed layer takes the dense layer predictions and applies the sigmoid \n",
    "    # activation function to all time steps.\n",
    "    outputs = tf.keras.layers.TimeDistributed(dense, name='outputs')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='DKT')\n",
    "\n",
    "    # Compile the model with our loss functions, optimizer, and metrics.\n",
    "    model.compile(loss=CustomBinaryCrossEntropy, \n",
    "                  optimizer=params['optimizer'], \n",
    "                  metrics=[AUC(), RMSE()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create our DKT model using an LSTM\n",
    "dkt_lstm = create_model_lstm(features_depth, skill_depth, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7c14fd-8d4a-4b20-b5c1-2587335ebe70",
   "metadata": {
    "id": "ec7c14fd-8d4a-4b20-b5c1-2587335ebe70"
   },
   "outputs": [],
   "source": [
    "def create_model_gru(nb_features, nb_skills, params):\n",
    "    \n",
    "    # Create a GRU model architecture\n",
    "    inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
    "\n",
    "    # We use a masking layer here to ignore our masked padding values\n",
    "    x = tf.keras.layers.Masking(mask_value=params['mask_value'])(inputs)\n",
    "\n",
    "    # This GRU layer is the crux of the model; we use our parameters to specify\n",
    "    # what this layer should look like (# of recurrent_units, fraction of dropout).\n",
    "    x = tf.keras.layers.GRU(params['recurrent_units'], return_sequences=True, dropout=params['dropout_rate'])(x)\n",
    "    \n",
    "    # We use a dense layer with the sigmoid function activation to map our predictions \n",
    "    # between 0 and 1.\n",
    "    dense = tf.keras.layers.Dense(nb_skills, activation='sigmoid')\n",
    "\n",
    "    # The TimeDistributed layer takes the dense layer predictions and applies the sigmoid \n",
    "    # activation function to all time steps.\n",
    "    outputs = tf.keras.layers.TimeDistributed(dense, name='outputs')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='DKT')\n",
    "\n",
    "    # Compile the model with our loss functions, optimizer, and metrics.\n",
    "    model.compile(loss=CustomBinaryCrossEntropy, \n",
    "                  optimizer=params['optimizer'], \n",
    "                  metrics=[AUC(), RMSE()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create our DKT model using a GRU\n",
    "dkt_gru = create_model_gru(features_depth, skill_depth, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BDF1YnZ77bGR",
   "metadata": {
    "id": "BDF1YnZ77bGR"
   },
   "source": [
    "### Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380dd28-4fe5-42e4-a32f-a21736fcdf70",
   "metadata": {
    "id": "c380dd28-4fe5-42e4-a32f-a21736fcdf70"
   },
   "source": [
    "Next we train the models and then evaluate them on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "649014c0-0a71-43ca-83c7-1b525c19f3d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "649014c0-0a71-43ca-83c7-1b525c19f3d9",
    "outputId": "e842e7fa-b78d-452a-e457-6d3dbe909d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "82/82 [==============================] - 30s 263ms/step - loss: 0.1912 - auc: 0.5020 - root_mean_squared_error: 0.4999 - val_loss: 0.1746 - val_auc: 0.6513 - val_root_mean_squared_error: 0.4939\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1872 - auc: 0.6381 - root_mean_squared_error: 0.4880 - val_loss: 0.1680 - val_auc: 0.6354 - val_root_mean_squared_error: 0.4786\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1798 - auc: 0.6609 - root_mean_squared_error: 0.4685 - val_loss: 0.1614 - val_auc: 0.6705 - val_root_mean_squared_error: 0.4606\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 21s 261ms/step - loss: 0.1739 - auc: 0.7023 - root_mean_squared_error: 0.4494 - val_loss: 0.1568 - val_auc: 0.7008 - val_root_mean_squared_error: 0.4477\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 19s 238ms/step - loss: 0.1712 - auc: 0.7339 - root_mean_squared_error: 0.4354 - val_loss: 0.1541 - val_auc: 0.7192 - val_root_mean_squared_error: 0.4389\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 0.1679 - auc: 0.7615 - root_mean_squared_error: 0.4244 - val_loss: 0.1517 - val_auc: 0.7376 - val_root_mean_squared_error: 0.4329\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 20s 230ms/step - loss: 0.1629 - auc: 0.7792 - root_mean_squared_error: 0.4176 - val_loss: 0.1504 - val_auc: 0.7550 - val_root_mean_squared_error: 0.4302\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 19s 239ms/step - loss: 0.1614 - auc: 0.7927 - root_mean_squared_error: 0.4113 - val_loss: 0.1484 - val_auc: 0.7620 - val_root_mean_squared_error: 0.4249\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1609 - auc: 0.8000 - root_mean_squared_error: 0.4072 - val_loss: 0.1474 - val_auc: 0.7659 - val_root_mean_squared_error: 0.4220\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 19s 240ms/step - loss: 0.1592 - auc: 0.8073 - root_mean_squared_error: 0.4031 - val_loss: 0.1465 - val_auc: 0.7705 - val_root_mean_squared_error: 0.4200\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 19s 239ms/step - loss: 0.1582 - auc: 0.8129 - root_mean_squared_error: 0.3996 - val_loss: 0.1456 - val_auc: 0.7748 - val_root_mean_squared_error: 0.4177\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 14s 176ms/step - loss: 0.1590 - auc: 0.8112 - root_mean_squared_error: 0.4005 - val_loss: 0.1444 - val_auc: 0.7796 - val_root_mean_squared_error: 0.4147\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 19s 170ms/step - loss: 0.1574 - auc: 0.8200 - root_mean_squared_error: 0.3950 - val_loss: 0.1436 - val_auc: 0.7825 - val_root_mean_squared_error: 0.4129\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1547 - auc: 0.8235 - root_mean_squared_error: 0.3926 - val_loss: 0.1430 - val_auc: 0.7851 - val_root_mean_squared_error: 0.4114\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.1548 - auc: 0.8253 - root_mean_squared_error: 0.3910 - val_loss: 0.1424 - val_auc: 0.7869 - val_root_mean_squared_error: 0.4101\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1553 - auc: 0.8268 - root_mean_squared_error: 0.3898 - val_loss: 0.1418 - val_auc: 0.7890 - val_root_mean_squared_error: 0.4086\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.1524 - auc: 0.8291 - root_mean_squared_error: 0.3882 - val_loss: 0.1413 - val_auc: 0.7904 - val_root_mean_squared_error: 0.4076\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1525 - auc: 0.8304 - root_mean_squared_error: 0.3871 - val_loss: 0.1408 - val_auc: 0.7918 - val_root_mean_squared_error: 0.4066\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1526 - auc: 0.8320 - root_mean_squared_error: 0.3856 - val_loss: 0.1404 - val_auc: 0.7936 - val_root_mean_squared_error: 0.4056\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.1526 - auc: 0.8332 - root_mean_squared_error: 0.3847 - val_loss: 0.1401 - val_auc: 0.7946 - val_root_mean_squared_error: 0.4049\n"
     ]
    }
   ],
   "source": [
    "# This line tells our training procedure to only save the best version of the model at any given time.\n",
    "ckp_callback = tf.keras.callbacks.ModelCheckpoint(params['best_model_weights'], \n",
    "                                                  save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Let's fit our LSTM model on the training data. This cell takes 8 minutes to run on Colab.\n",
    "history = dkt_lstm.fit(tf_train, epochs=params['epochs'], steps_per_epoch=params['train_size']-1, \n",
    "                       validation_data=tf_val, validation_steps=params['val_size'],\n",
    "                       callbacks=[ckp_callback], verbose=params['verbose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "AFWPgmhpvul7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AFWPgmhpvul7",
    "outputId": "61d3fa31-dd9b-4e86-a23b-de932d4d837c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 48ms/step - loss: 0.1303 - auc: 0.8537 - root_mean_squared_error: 0.3658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8536582589149475,\n",
       " 'loss': 0.13026706874370575,\n",
       " 'root_mean_squared_error': 0.3657849431037903}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load the LSTM model with the best performance, and evaluate it on the test set. \n",
    "dkt_lstm.load_weights(params['best_model_weights'])\n",
    "dkt_lstm.evaluate(tf_test, steps=params['test_size'], verbose=params['verbose'], return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d224ac3-0c5b-4824-90ed-c345b798fcbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d224ac3-0c5b-4824-90ed-c345b798fcbf",
    "outputId": "4e10b80c-6db2-4123-fd6c-d06d35b23488"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "82/82 [==============================] - 25s 268ms/step - loss: 0.1899 - auc: 0.5613 - root_mean_squared_error: 0.4968 - val_loss: 0.1727 - val_auc: 0.6738 - val_root_mean_squared_error: 0.4902\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 21s 258ms/step - loss: 0.1859 - auc: 0.6851 - root_mean_squared_error: 0.4853 - val_loss: 0.1676 - val_auc: 0.6995 - val_root_mean_squared_error: 0.4783\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 21s 258ms/step - loss: 0.1790 - auc: 0.7170 - root_mean_squared_error: 0.4688 - val_loss: 0.1599 - val_auc: 0.7000 - val_root_mean_squared_error: 0.4577\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 21s 257ms/step - loss: 0.1724 - auc: 0.7307 - root_mean_squared_error: 0.4448 - val_loss: 0.1550 - val_auc: 0.7227 - val_root_mean_squared_error: 0.4446\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 21s 254ms/step - loss: 0.1690 - auc: 0.7634 - root_mean_squared_error: 0.4294 - val_loss: 0.1517 - val_auc: 0.7409 - val_root_mean_squared_error: 0.4360\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1662 - auc: 0.7820 - root_mean_squared_error: 0.4195 - val_loss: 0.1495 - val_auc: 0.7534 - val_root_mean_squared_error: 0.4303\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 21s 241ms/step - loss: 0.1611 - auc: 0.7991 - root_mean_squared_error: 0.4107 - val_loss: 0.1471 - val_auc: 0.7646 - val_root_mean_squared_error: 0.4241\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 21s 255ms/step - loss: 0.1593 - auc: 0.8089 - root_mean_squared_error: 0.4041 - val_loss: 0.1458 - val_auc: 0.7700 - val_root_mean_squared_error: 0.4208\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 21s 255ms/step - loss: 0.1586 - auc: 0.8159 - root_mean_squared_error: 0.3993 - val_loss: 0.1442 - val_auc: 0.7770 - val_root_mean_squared_error: 0.4166\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 21s 257ms/step - loss: 0.1569 - auc: 0.8205 - root_mean_squared_error: 0.3954 - val_loss: 0.1434 - val_auc: 0.7793 - val_root_mean_squared_error: 0.4145\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 21s 257ms/step - loss: 0.1561 - auc: 0.8239 - root_mean_squared_error: 0.3927 - val_loss: 0.1424 - val_auc: 0.7832 - val_root_mean_squared_error: 0.4119\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 14s 177ms/step - loss: 0.1571 - auc: 0.8199 - root_mean_squared_error: 0.3942 - val_loss: 0.1418 - val_auc: 0.7854 - val_root_mean_squared_error: 0.4102\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 21s 176ms/step - loss: 0.1559 - auc: 0.8277 - root_mean_squared_error: 0.3890 - val_loss: 0.1411 - val_auc: 0.7888 - val_root_mean_squared_error: 0.4082\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 21s 263ms/step - loss: 0.1532 - auc: 0.8296 - root_mean_squared_error: 0.3875 - val_loss: 0.1406 - val_auc: 0.7901 - val_root_mean_squared_error: 0.4072\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 21s 256ms/step - loss: 0.1537 - auc: 0.8307 - root_mean_squared_error: 0.3862 - val_loss: 0.1402 - val_auc: 0.7919 - val_root_mean_squared_error: 0.4061\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 21s 258ms/step - loss: 0.1541 - auc: 0.8322 - root_mean_squared_error: 0.3852 - val_loss: 0.1398 - val_auc: 0.7940 - val_root_mean_squared_error: 0.4051\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 21s 257ms/step - loss: 0.1514 - auc: 0.8333 - root_mean_squared_error: 0.3843 - val_loss: 0.1394 - val_auc: 0.7954 - val_root_mean_squared_error: 0.4042\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 21s 259ms/step - loss: 0.1517 - auc: 0.8341 - root_mean_squared_error: 0.3836 - val_loss: 0.1390 - val_auc: 0.7968 - val_root_mean_squared_error: 0.4034\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 21s 258ms/step - loss: 0.1521 - auc: 0.8342 - root_mean_squared_error: 0.3831 - val_loss: 0.1388 - val_auc: 0.7976 - val_root_mean_squared_error: 0.4029\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 21s 256ms/step - loss: 0.1523 - auc: 0.8351 - root_mean_squared_error: 0.3825 - val_loss: 0.1386 - val_auc: 0.7985 - val_root_mean_squared_error: 0.4024\n"
     ]
    }
   ],
   "source": [
    "# This line tells our training procedure to only save the best version of the model at any given time.\n",
    "ckp_callback = tf.keras.callbacks.ModelCheckpoint(params['best_model_weights'], \n",
    "                                                  save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Let's fit our GRU model on the training data. This cell takes 8 minutes to run on Colab.\n",
    "history = dkt_gru.fit(tf_train, epochs=params['epochs'], steps_per_epoch=params['train_size']-1, \n",
    "                       validation_data=tf_val, validation_steps=params['val_size'],\n",
    "                       callbacks=[ckp_callback], verbose=params['verbose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vWkpS2fzC0MS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWkpS2fzC0MS",
    "outputId": "1a8e2d2f-a89e-4960-abd9-1f0d9301e416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 50ms/step - loss: 0.1291 - auc: 0.8590 - root_mean_squared_error: 0.3618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8589878082275391,\n",
       " 'loss': 0.12905816733837128,\n",
       " 'root_mean_squared_error': 0.3618166148662567}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load the GRU model with the best performance, and evaluate it on the test set. \n",
    "dkt_gru.load_weights(params['best_model_weights'])\n",
    "dkt_gru.evaluate(tf_test, steps=params['test_size'], verbose=params['verbose'], return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd0d25-7ac3-4e0e-883f-3a35893d065e",
   "metadata": {
    "id": "adcd0d25-7ac3-4e0e-883f-3a35893d065e"
   },
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "As we have seen, we need to specify a lot of hyperparameters. In a next step, we perform a small grid search for the number of recurrent units in the LSTM: {8, 16, 32, 64}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6YRkJNteF7q0",
   "metadata": {
    "id": "6YRkJNteF7q0"
   },
   "outputs": [],
   "source": [
    "# Modify the dictionary of parameters so that each parameter maps to a list of possibilities.\n",
    "# In this case, we're only searching over the recurrent_units and leaving the rest of the \n",
    "# parameters fixed to their default values.\n",
    "params_space = {param: [value] for param, value in params.items()}\n",
    "params_space['recurrent_units'] = [8, 16, 32, 64]\n",
    "params_grid = ParameterGrid(params_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cVQLRMVgGRce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVQLRMVgGRce",
    "outputId": "09b512d0-4098-40f4-9efc-76e59fafe54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "82/82 [==============================] - 24s 258ms/step - loss: 0.1909 - auc: 0.5542 - root_mean_squared_error: 0.4989 - val_loss: 0.1749 - val_auc: 0.6300 - val_root_mean_squared_error: 0.4953\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.1881 - auc: 0.6433 - root_mean_squared_error: 0.4910 - val_loss: 0.1703 - val_auc: 0.6331 - val_root_mean_squared_error: 0.4844\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1829 - auc: 0.6341 - root_mean_squared_error: 0.4779 - val_loss: 0.1656 - val_auc: 0.6486 - val_root_mean_squared_error: 0.4724\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1788 - auc: 0.6597 - root_mean_squared_error: 0.4652 - val_loss: 0.1616 - val_auc: 0.6718 - val_root_mean_squared_error: 0.4630\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.1764 - auc: 0.6939 - root_mean_squared_error: 0.4541 - val_loss: 0.1587 - val_auc: 0.6885 - val_root_mean_squared_error: 0.4562\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 0.1736 - auc: 0.7170 - root_mean_squared_error: 0.4457 - val_loss: 0.1565 - val_auc: 0.7001 - val_root_mean_squared_error: 0.4504\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 20s 230ms/step - loss: 0.1690 - auc: 0.7316 - root_mean_squared_error: 0.4400 - val_loss: 0.1547 - val_auc: 0.7136 - val_root_mean_squared_error: 0.4455\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 20s 250ms/step - loss: 0.1673 - auc: 0.7470 - root_mean_squared_error: 0.4333 - val_loss: 0.1531 - val_auc: 0.7231 - val_root_mean_squared_error: 0.4413\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 0.1666 - auc: 0.7588 - root_mean_squared_error: 0.4281 - val_loss: 0.1518 - val_auc: 0.7322 - val_root_mean_squared_error: 0.4377\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1650 - auc: 0.7686 - root_mean_squared_error: 0.4237 - val_loss: 0.1506 - val_auc: 0.7391 - val_root_mean_squared_error: 0.4344\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1640 - auc: 0.7769 - root_mean_squared_error: 0.4198 - val_loss: 0.1495 - val_auc: 0.7442 - val_root_mean_squared_error: 0.4313\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 14s 173ms/step - loss: 0.1647 - auc: 0.7774 - root_mean_squared_error: 0.4192 - val_loss: 0.1487 - val_auc: 0.7497 - val_root_mean_squared_error: 0.4291\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 20s 173ms/step - loss: 0.1628 - auc: 0.7895 - root_mean_squared_error: 0.4132 - val_loss: 0.1478 - val_auc: 0.7547 - val_root_mean_squared_error: 0.4265\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.1599 - auc: 0.7959 - root_mean_squared_error: 0.4101 - val_loss: 0.1470 - val_auc: 0.7593 - val_root_mean_squared_error: 0.4243\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1600 - auc: 0.8005 - root_mean_squared_error: 0.4076 - val_loss: 0.1463 - val_auc: 0.7629 - val_root_mean_squared_error: 0.4224\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 20s 248ms/step - loss: 0.1603 - auc: 0.8046 - root_mean_squared_error: 0.4054 - val_loss: 0.1456 - val_auc: 0.7675 - val_root_mean_squared_error: 0.4206\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1572 - auc: 0.8086 - root_mean_squared_error: 0.4034 - val_loss: 0.1449 - val_auc: 0.7708 - val_root_mean_squared_error: 0.4188\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1571 - auc: 0.8125 - root_mean_squared_error: 0.4011 - val_loss: 0.1445 - val_auc: 0.7737 - val_root_mean_squared_error: 0.4177\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1572 - auc: 0.8158 - root_mean_squared_error: 0.3992 - val_loss: 0.1440 - val_auc: 0.7766 - val_root_mean_squared_error: 0.4161\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1572 - auc: 0.8185 - root_mean_squared_error: 0.3975 - val_loss: 0.1434 - val_auc: 0.7791 - val_root_mean_squared_error: 0.4149\n",
      "20/20 [==============================] - 1s 53ms/step - loss: 0.1434 - auc: 0.7791 - root_mean_squared_error: 0.4149\n",
      "Epoch 1/20\n",
      "82/82 [==============================] - 24s 263ms/step - loss: 0.1899 - auc: 0.6045 - root_mean_squared_error: 0.4960 - val_loss: 0.1728 - val_auc: 0.6694 - val_root_mean_squared_error: 0.4900\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.1846 - auc: 0.6548 - root_mean_squared_error: 0.4821 - val_loss: 0.1650 - val_auc: 0.6430 - val_root_mean_squared_error: 0.4701\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1771 - auc: 0.6752 - root_mean_squared_error: 0.4604 - val_loss: 0.1588 - val_auc: 0.6902 - val_root_mean_squared_error: 0.4522\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 19s 239ms/step - loss: 0.1717 - auc: 0.7229 - root_mean_squared_error: 0.4418 - val_loss: 0.1550 - val_auc: 0.7196 - val_root_mean_squared_error: 0.4431\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1694 - auc: 0.7515 - root_mean_squared_error: 0.4301 - val_loss: 0.1521 - val_auc: 0.7311 - val_root_mean_squared_error: 0.4355\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.1665 - auc: 0.7693 - root_mean_squared_error: 0.4218 - val_loss: 0.1500 - val_auc: 0.7422 - val_root_mean_squared_error: 0.4302\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 20s 230ms/step - loss: 0.1622 - auc: 0.7874 - root_mean_squared_error: 0.4145 - val_loss: 0.1493 - val_auc: 0.7480 - val_root_mean_squared_error: 0.4269\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1605 - auc: 0.7988 - root_mean_squared_error: 0.4088 - val_loss: 0.1471 - val_auc: 0.7668 - val_root_mean_squared_error: 0.4221\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.1599 - auc: 0.8080 - root_mean_squared_error: 0.4042 - val_loss: 0.1460 - val_auc: 0.7706 - val_root_mean_squared_error: 0.4191\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1582 - auc: 0.8145 - root_mean_squared_error: 0.4001 - val_loss: 0.1448 - val_auc: 0.7757 - val_root_mean_squared_error: 0.4164\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1574 - auc: 0.8193 - root_mean_squared_error: 0.3969 - val_loss: 0.1439 - val_auc: 0.7802 - val_root_mean_squared_error: 0.4140\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 14s 174ms/step - loss: 0.1581 - auc: 0.8163 - root_mean_squared_error: 0.3978 - val_loss: 0.1431 - val_auc: 0.7842 - val_root_mean_squared_error: 0.4122\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 20s 171ms/step - loss: 0.1565 - auc: 0.8251 - root_mean_squared_error: 0.3923 - val_loss: 0.1425 - val_auc: 0.7860 - val_root_mean_squared_error: 0.4107\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 19s 240ms/step - loss: 0.1539 - auc: 0.8272 - root_mean_squared_error: 0.3903 - val_loss: 0.1418 - val_auc: 0.7881 - val_root_mean_squared_error: 0.4093\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1539 - auc: 0.8290 - root_mean_squared_error: 0.3886 - val_loss: 0.1413 - val_auc: 0.7895 - val_root_mean_squared_error: 0.4083\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1545 - auc: 0.8297 - root_mean_squared_error: 0.3877 - val_loss: 0.1407 - val_auc: 0.7919 - val_root_mean_squared_error: 0.4070\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1517 - auc: 0.8308 - root_mean_squared_error: 0.3866 - val_loss: 0.1404 - val_auc: 0.7925 - val_root_mean_squared_error: 0.4062\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1518 - auc: 0.8320 - root_mean_squared_error: 0.3856 - val_loss: 0.1399 - val_auc: 0.7938 - val_root_mean_squared_error: 0.4055\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 20s 242ms/step - loss: 0.1521 - auc: 0.8331 - root_mean_squared_error: 0.3845 - val_loss: 0.1396 - val_auc: 0.7948 - val_root_mean_squared_error: 0.4047\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1522 - auc: 0.8339 - root_mean_squared_error: 0.3838 - val_loss: 0.1394 - val_auc: 0.7955 - val_root_mean_squared_error: 0.4044\n",
      "20/20 [==============================] - 1s 52ms/step - loss: 0.1394 - auc: 0.7955 - root_mean_squared_error: 0.4044\n",
      "Epoch 1/20\n",
      "82/82 [==============================] - 24s 258ms/step - loss: 0.1893 - auc: 0.5323 - root_mean_squared_error: 0.4960 - val_loss: 0.1685 - val_auc: 0.5883 - val_root_mean_squared_error: 0.4792\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1809 - auc: 0.6010 - root_mean_squared_error: 0.4710 - val_loss: 0.1609 - val_auc: 0.6768 - val_root_mean_squared_error: 0.4575\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1730 - auc: 0.7068 - root_mean_squared_error: 0.4466 - val_loss: 0.1554 - val_auc: 0.7092 - val_root_mean_squared_error: 0.4436\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1682 - auc: 0.7540 - root_mean_squared_error: 0.4288 - val_loss: 0.1519 - val_auc: 0.7318 - val_root_mean_squared_error: 0.4345\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1661 - auc: 0.7795 - root_mean_squared_error: 0.4163 - val_loss: 0.1492 - val_auc: 0.7564 - val_root_mean_squared_error: 0.4258\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.1635 - auc: 0.7951 - root_mean_squared_error: 0.4096 - val_loss: 0.1466 - val_auc: 0.7685 - val_root_mean_squared_error: 0.4197\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 20s 233ms/step - loss: 0.1587 - auc: 0.8111 - root_mean_squared_error: 0.4013 - val_loss: 0.1453 - val_auc: 0.7764 - val_root_mean_squared_error: 0.4166\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1575 - auc: 0.8166 - root_mean_squared_error: 0.3977 - val_loss: 0.1439 - val_auc: 0.7824 - val_root_mean_squared_error: 0.4131\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 0.1568 - auc: 0.8231 - root_mean_squared_error: 0.3932 - val_loss: 0.1428 - val_auc: 0.7860 - val_root_mean_squared_error: 0.4105\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1551 - auc: 0.8271 - root_mean_squared_error: 0.3901 - val_loss: 0.1419 - val_auc: 0.7895 - val_root_mean_squared_error: 0.4087\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1542 - auc: 0.8306 - root_mean_squared_error: 0.3876 - val_loss: 0.1410 - val_auc: 0.7910 - val_root_mean_squared_error: 0.4072\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 14s 175ms/step - loss: 0.1551 - auc: 0.8263 - root_mean_squared_error: 0.3895 - val_loss: 0.1403 - val_auc: 0.7937 - val_root_mean_squared_error: 0.4056\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 20s 173ms/step - loss: 0.1535 - auc: 0.8341 - root_mean_squared_error: 0.3845 - val_loss: 0.1400 - val_auc: 0.7942 - val_root_mean_squared_error: 0.4053\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1511 - auc: 0.8352 - root_mean_squared_error: 0.3833 - val_loss: 0.1396 - val_auc: 0.7954 - val_root_mean_squared_error: 0.4047\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1513 - auc: 0.8359 - root_mean_squared_error: 0.3826 - val_loss: 0.1393 - val_auc: 0.7961 - val_root_mean_squared_error: 0.4042\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.1521 - auc: 0.8361 - root_mean_squared_error: 0.3821 - val_loss: 0.1385 - val_auc: 0.7976 - val_root_mean_squared_error: 0.4030\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1493 - auc: 0.8375 - root_mean_squared_error: 0.3813 - val_loss: 0.1383 - val_auc: 0.7979 - val_root_mean_squared_error: 0.4028\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1495 - auc: 0.8384 - root_mean_squared_error: 0.3807 - val_loss: 0.1378 - val_auc: 0.7996 - val_root_mean_squared_error: 0.4020\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.1498 - auc: 0.8396 - root_mean_squared_error: 0.3794 - val_loss: 0.1377 - val_auc: 0.7999 - val_root_mean_squared_error: 0.4017\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 20s 243ms/step - loss: 0.1500 - auc: 0.8395 - root_mean_squared_error: 0.3794 - val_loss: 0.1376 - val_auc: 0.8005 - val_root_mean_squared_error: 0.4014\n",
      "20/20 [==============================] - 1s 51ms/step - loss: 0.1376 - auc: 0.8005 - root_mean_squared_error: 0.4014\n",
      "Epoch 1/20\n",
      "82/82 [==============================] - 25s 262ms/step - loss: 0.1856 - auc: 0.6026 - root_mean_squared_error: 0.4878 - val_loss: 0.1664 - val_auc: 0.6016 - val_root_mean_squared_error: 0.4763\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 20s 250ms/step - loss: 0.1744 - auc: 0.7037 - root_mean_squared_error: 0.4507 - val_loss: 0.1549 - val_auc: 0.7137 - val_root_mean_squared_error: 0.4428\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1668 - auc: 0.7659 - root_mean_squared_error: 0.4264 - val_loss: 0.1499 - val_auc: 0.7484 - val_root_mean_squared_error: 0.4294\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1618 - auc: 0.7968 - root_mean_squared_error: 0.4087 - val_loss: 0.1465 - val_auc: 0.7574 - val_root_mean_squared_error: 0.4218\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 0.1599 - auc: 0.8117 - root_mean_squared_error: 0.3984 - val_loss: 0.1444 - val_auc: 0.7667 - val_root_mean_squared_error: 0.4169\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.1579 - auc: 0.8185 - root_mean_squared_error: 0.3934 - val_loss: 0.1427 - val_auc: 0.7748 - val_root_mean_squared_error: 0.4138\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 20s 236ms/step - loss: 0.1538 - auc: 0.8250 - root_mean_squared_error: 0.3891 - val_loss: 0.1421 - val_auc: 0.7763 - val_root_mean_squared_error: 0.4132\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 0.1531 - auc: 0.8272 - root_mean_squared_error: 0.3873 - val_loss: 0.1414 - val_auc: 0.7794 - val_root_mean_squared_error: 0.4107\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1528 - auc: 0.8293 - root_mean_squared_error: 0.3853 - val_loss: 0.1401 - val_auc: 0.7842 - val_root_mean_squared_error: 0.4088\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 20s 245ms/step - loss: 0.1516 - auc: 0.8322 - root_mean_squared_error: 0.3835 - val_loss: 0.1389 - val_auc: 0.7922 - val_root_mean_squared_error: 0.4051\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 21s 255ms/step - loss: 0.1510 - auc: 0.8353 - root_mean_squared_error: 0.3817 - val_loss: 0.1389 - val_auc: 0.7944 - val_root_mean_squared_error: 0.4048\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 14s 178ms/step - loss: 0.1522 - auc: 0.8309 - root_mean_squared_error: 0.3848 - val_loss: 0.1386 - val_auc: 0.7930 - val_root_mean_squared_error: 0.4054\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 20s 175ms/step - loss: 0.1506 - auc: 0.8384 - root_mean_squared_error: 0.3799 - val_loss: 0.1381 - val_auc: 0.7967 - val_root_mean_squared_error: 0.4032\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 20s 247ms/step - loss: 0.1484 - auc: 0.8403 - root_mean_squared_error: 0.3786 - val_loss: 0.1377 - val_auc: 0.7972 - val_root_mean_squared_error: 0.4029\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 20s 248ms/step - loss: 0.1490 - auc: 0.8410 - root_mean_squared_error: 0.3784 - val_loss: 0.1376 - val_auc: 0.7970 - val_root_mean_squared_error: 0.4025\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1494 - auc: 0.8413 - root_mean_squared_error: 0.3780 - val_loss: 0.1395 - val_auc: 0.7913 - val_root_mean_squared_error: 0.4077\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 20s 249ms/step - loss: 0.1474 - auc: 0.8401 - root_mean_squared_error: 0.3791 - val_loss: 0.1376 - val_auc: 0.7979 - val_root_mean_squared_error: 0.4029\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1475 - auc: 0.8411 - root_mean_squared_error: 0.3779 - val_loss: 0.1371 - val_auc: 0.7996 - val_root_mean_squared_error: 0.4014\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 20s 244ms/step - loss: 0.1474 - auc: 0.8435 - root_mean_squared_error: 0.3765 - val_loss: 0.1367 - val_auc: 0.8007 - val_root_mean_squared_error: 0.4007\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 20s 246ms/step - loss: 0.1473 - auc: 0.8445 - root_mean_squared_error: 0.3758 - val_loss: 0.1366 - val_auc: 0.8014 - val_root_mean_squared_error: 0.4004\n",
      "20/20 [==============================] - 1s 55ms/step - loss: 0.1366 - auc: 0.8014 - root_mean_squared_error: 0.4004\n"
     ]
    }
   ],
   "source": [
    "# For each combination of candidate parameters, fit a model on the training set \n",
    "# and evaluate it on the validation set (as we've seen in Lecture 5). \n",
    "\n",
    "# NOTE: This cell will take 40 minutes to run.\n",
    "results = {}\n",
    "\n",
    "# For each parameter setting in the grid search of parameters\n",
    "for params_i in params_grid:\n",
    "\n",
    "    # Create a LSTM model with the specific parameter setting params_i\n",
    "    dkt_lstm = create_model_lstm(features_depth, skill_depth, params_i)\n",
    "\n",
    "    save_model_name = params_i['best_model_weights'] + str(params_i['recurrent_units'])\n",
    "\n",
    "    # Save the best version of the model through the training epochs\n",
    "    ckp_callback = tf.keras.callbacks.ModelCheckpoint(save_model_name, \n",
    "                                                      save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    # Fit the model on the training data with the appropriate parameters  \n",
    "    dkt_lstm.fit(tf_train, \n",
    "                 epochs=params_i['epochs'],\n",
    "                 steps_per_epoch=params_i['train_size']-1, \n",
    "                 validation_data=tf_val, \n",
    "                 validation_steps=params_i['val_size'],\n",
    "                 callbacks=[ckp_callback],\n",
    "                 verbose=params_i['verbose'])\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    results[params_i['recurrent_units']] = dkt_lstm.evaluate(tf_val, \n",
    "                                                             steps=params_i['val_size'], \n",
    "                                                             verbose=params_i['verbose'], \n",
    "                                                             return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42YW9E5hH7vo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42YW9E5hH7vo",
    "outputId": "1da0f4bd-cdfe-4392-b6bb-3c44f247a7b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort candidate parameters according to their accuracy\n",
    "results = sorted(results.items(), key=lambda x: x[1]['auc'], reverse=True)\n",
    "\n",
    "# Obtain the best parameters\n",
    "best_params = results[0][0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "V4PLC5CPIDVK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4PLC5CPIDVK",
    "outputId": "2afa477c-e492-4d73-8af6-15f293e96f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 49ms/step - loss: 0.1272 - auc: 0.8622 - root_mean_squared_error: 0.3586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.8622029423713684,\n",
       " 'loss': 0.12718340754508972,\n",
       " 'root_mean_squared_error': 0.3585869371891022}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model variant from the hyperparameter gridsearch\n",
    "dkt_lstm.load_weights(params['best_model_weights'] + str(best_params))\n",
    "dkt_lstm.evaluate(tf_test, steps=params['test_size'], \n",
    "                       verbose=params['verbose'], \n",
    "                       return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4efd2-67ca-4c54-b1b9-195a18ee6845",
   "metadata": {
    "id": "53c4efd2-67ca-4c54-b1b9-195a18ee6845"
   },
   "source": [
    "## Tracing and Time-Series Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881d886-8f14-42c2-87cb-a964fc057fa6",
   "metadata": {
    "id": "0881d886-8f14-42c2-87cb-a964fc057fa6"
   },
   "source": [
    "Next, we perform experiments with recurrent neural networks for tracing as well as the time series task. We first load the data for the tracing task. It stems from a massive open online course (MOOC) hosted by EPFL. We first load the features as well as the labels to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3c8271-1074-4ec7-a0f9-44862b35b02f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da3c8271-1074-4ec7-a0f9-44862b35b02f",
    "outputId": "eff194e3-88d5-4acc-962d-bb060a8a14f2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'week', 'TotalClicksVideoLoad', 'AvgWatchedWeeklyProp',\n",
       "       'StdWatchedWeeklyProp', 'AvgReplayedWeeklyProp',\n",
       "       'StdReplayedWeeklyProp', 'AvgInterruptedWeeklyProp',\n",
       "       'StdInterruptedWeeklyProp', 'TotalClicksVideoConati',\n",
       "       'FrequencyEventVideo', 'FrequencyEventLoad', 'FrequencyEventVideoPlay',\n",
       "       'FrequencyEventVideoPause', 'FrequencyEventVideoStop',\n",
       "       'FrequencyEventVideoSeekBackward', 'FrequencyEventVideoSeekForward',\n",
       "       'FrequencyEventVideoSpeedChange', 'AvgSeekLength', 'StdSeekLength',\n",
       "       'AvgPauseDuration', 'StdPauseDuration', 'AvgTimeSpeedingUp',\n",
       "       'StdTimeSpeedingUp', 'RegPeakTimeDayHour', 'RegPeriodicityM1',\n",
       "       'DelayLecture', 'TotalClicks', 'NumberOfSessions', 'TotalTimeSessions',\n",
       "       'AvgTimeSessions', 'StdTimeBetweenSessions', 'StdTimeSessions',\n",
       "       'TotalClicksWeekday', 'TotalClicksWeekend', 'RatioClicksWeekendDay',\n",
       "       'TotalClicksVideoChen', 'TotalClicksProblem', 'TotalTimeProblem',\n",
       "       'TotalTimeVideo', 'CompetencyAlignment', 'CompetencyAnticipation',\n",
       "       'ContentAlignment', 'ContentAnticipation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mooc_feat = pd.read_csv(DATA_DIR + 'mooc_feat.csv', low_memory=False)\n",
    "mooc_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce6eed4-1698-41c3-a319-d5149d979407",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "dce6eed4-1698-41c3-a319-d5149d979407",
    "outputId": "a653b923-02bd-40ff-8985-0595bc7b2500"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c81f7938-b0e5-471e-a131-77fefc5c29b1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>week</th>\n",
       "      <th>quiz_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1593</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1593</td>\n",
       "      <td>2</td>\n",
       "      <td>0.807141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1593</td>\n",
       "      <td>3</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59685</th>\n",
       "      <td>3353959</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59686</th>\n",
       "      <td>3353959</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59687</th>\n",
       "      <td>3353959</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59688</th>\n",
       "      <td>3353959</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59689</th>\n",
       "      <td>3353959</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59690 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c81f7938-b0e5-471e-a131-77fefc5c29b1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c81f7938-b0e5-471e-a131-77fefc5c29b1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c81f7938-b0e5-471e-a131-77fefc5c29b1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       user_id  week  quiz_correct\n",
       "0         1593     0      0.929825\n",
       "1         1593     1           NaN\n",
       "2         1593     2      0.807141\n",
       "3         1593     3      0.960000\n",
       "4         1593     4      0.900000\n",
       "...        ...   ...           ...\n",
       "59685  3353959     5           NaN\n",
       "59686  3353959     6           NaN\n",
       "59687  3353959     7           NaN\n",
       "59688  3353959     8           NaN\n",
       "59689  3353959     9           NaN\n",
       "\n",
       "[59690 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mooc_quizzes = pd.read_csv(DATA_DIR + 'mooc_quizzes.csv', low_memory=False)\n",
    "display(mooc_quizzes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IXbziXoUC25k",
   "metadata": {
    "id": "IXbziXoUC25k"
   },
   "source": [
    "### Tracing: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vcuUz1niMQNp",
   "metadata": {
    "id": "vcuUz1niMQNp"
   },
   "outputs": [],
   "source": [
    "# Normalize all the features with min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "mooc_feat.iloc[:, 2:] = scaler.fit_transform(mooc_feat.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c911f5ff-e2a8-43fa-983b-d0dc0137e41c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c911f5ff-e2a8-43fa-983b-d0dc0137e41c",
    "outputId": "8ab70186-4e22-4c34-9cac-22b49caa5387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique students in the dataset: 5969\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique students in the dataset:\", len(set(mooc_feat['user_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec606bd-cf1d-4a48-ad49-2b4848d1bd6f",
   "metadata": {
    "id": "dec606bd-cf1d-4a48-ad49-2b4848d1bd6f"
   },
   "source": [
    "In this analysis, we want to predict **weekly quiz performance** of the students. We perform the following preprocessing steps to prepare our data:\n",
    "- First, we observe from the data frame mooc_quizzes that quite a number of students have not solved quizzes in all weeks. We will use a mask to ignore weeks for students with missing quiz answers. We create a new data frame df_y (the outcome), where we replace NaNs (for quiz_correct) with -1. We also create a data frame df_x, where we replace the according input feature values with -1.\n",
    "\n",
    "- Second, we bring df_y and df_x to an appropriate shape.\n",
    "\n",
    "  df_y should become a NumPy array of size:\n",
    "\n",
    "  `size(df_y) = num_of_students * num_of_weeks`\n",
    "\n",
    "  df_x should become a NumPy array of size:\n",
    "\n",
    "  `size(df_x) = num_of_students * num_of_weeks * num_of_features`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zQNXIR62F9YQ",
   "metadata": {
    "id": "zQNXIR62F9YQ"
   },
   "source": [
    "We create a data frame `df_x`, where we ignore weeks for students with missing quiz answers by filling in the appropriate feature values with -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hIDieWdrB8GI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "hIDieWdrB8GI",
    "outputId": "3891b41b-fec6-4121-d51c-3fd8dc5f4920"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4ba938f0-3c2a-4bcd-901f-c3f9d64ba02a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>week</th>\n",
       "      <th>TotalClicksVideoLoad</th>\n",
       "      <th>AvgWatchedWeeklyProp</th>\n",
       "      <th>StdWatchedWeeklyProp</th>\n",
       "      <th>AvgReplayedWeeklyProp</th>\n",
       "      <th>StdReplayedWeeklyProp</th>\n",
       "      <th>AvgInterruptedWeeklyProp</th>\n",
       "      <th>StdInterruptedWeeklyProp</th>\n",
       "      <th>TotalClicksVideoConati</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalClicksWeekend</th>\n",
       "      <th>RatioClicksWeekendDay</th>\n",
       "      <th>TotalClicksVideoChen</th>\n",
       "      <th>TotalClicksProblem</th>\n",
       "      <th>TotalTimeProblem</th>\n",
       "      <th>TotalTimeVideo</th>\n",
       "      <th>CompetencyAlignment</th>\n",
       "      <th>CompetencyAnticipation</th>\n",
       "      <th>ContentAlignment</th>\n",
       "      <th>ContentAnticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.576652</td>\n",
       "      <td>0.183632</td>\n",
       "      <td>0.239107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.318007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17476</td>\n",
       "      <td>0.340702</td>\n",
       "      <td>0.225483</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.163398</td>\n",
       "      <td>0.183748</td>\n",
       "      <td>0.222652</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1593</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1593</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.175734</td>\n",
       "      <td>0.239107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.490418</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17476</td>\n",
       "      <td>0.340702</td>\n",
       "      <td>0.225483</td>\n",
       "      <td>0.271355</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.183748</td>\n",
       "      <td>0.222652</td>\n",
       "      <td>0.567071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1593</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.175734</td>\n",
       "      <td>0.239107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.289242</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.505589</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17476</td>\n",
       "      <td>0.340702</td>\n",
       "      <td>0.225483</td>\n",
       "      <td>0.247526</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.183748</td>\n",
       "      <td>0.222652</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.175734</td>\n",
       "      <td>0.239107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.163399</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.186785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17476</td>\n",
       "      <td>0.340702</td>\n",
       "      <td>0.205682</td>\n",
       "      <td>0.247526</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.179129</td>\n",
       "      <td>0.183763</td>\n",
       "      <td>0.222659</td>\n",
       "      <td>0.362382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59685</th>\n",
       "      <td>3353959</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59686</th>\n",
       "      <td>3353959</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59687</th>\n",
       "      <td>3353959</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59688</th>\n",
       "      <td>3353959</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59689</th>\n",
       "      <td>3353959</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59690 rows × 44 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ba938f0-3c2a-4bcd-901f-c3f9d64ba02a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4ba938f0-3c2a-4bcd-901f-c3f9d64ba02a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4ba938f0-3c2a-4bcd-901f-c3f9d64ba02a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       user_id  week  TotalClicksVideoLoad  AvgWatchedWeeklyProp  \\\n",
       "0         1593     0              0.576652              0.183632   \n",
       "1         1593     1             -1.000000             -1.000000   \n",
       "2         1593     2              0.500000              0.175734   \n",
       "3         1593     3              0.500000              0.175734   \n",
       "4         1593     4              0.500000              0.175734   \n",
       "...        ...   ...                   ...                   ...   \n",
       "59685  3353959     5             -1.000000             -1.000000   \n",
       "59686  3353959     6             -1.000000             -1.000000   \n",
       "59687  3353959     7             -1.000000             -1.000000   \n",
       "59688  3353959     8             -1.000000             -1.000000   \n",
       "59689  3353959     9             -1.000000             -1.000000   \n",
       "\n",
       "       StdWatchedWeeklyProp  AvgReplayedWeeklyProp  StdReplayedWeeklyProp  \\\n",
       "0                  0.239107                    0.5               0.179129   \n",
       "1                 -1.000000                   -1.0              -1.000000   \n",
       "2                  0.239107                    0.5               0.179129   \n",
       "3                  0.239107                    0.5               0.289242   \n",
       "4                  0.239107                    0.5               0.163399   \n",
       "...                     ...                    ...                    ...   \n",
       "59685             -1.000000                   -1.0              -1.000000   \n",
       "59686             -1.000000                   -1.0              -1.000000   \n",
       "59687             -1.000000                   -1.0              -1.000000   \n",
       "59688             -1.000000                   -1.0              -1.000000   \n",
       "59689             -1.000000                   -1.0              -1.000000   \n",
       "\n",
       "       AvgInterruptedWeeklyProp  StdInterruptedWeeklyProp  \\\n",
       "0                      0.179129                  0.500000   \n",
       "1                     -1.000000                 -1.000000   \n",
       "2                      0.179129                  0.490418   \n",
       "3                      0.163399                  0.505589   \n",
       "4                      0.179129                  0.500000   \n",
       "...                         ...                       ...   \n",
       "59685                 -1.000000                 -1.000000   \n",
       "59686                 -1.000000                 -1.000000   \n",
       "59687                 -1.000000                 -1.000000   \n",
       "59688                 -1.000000                 -1.000000   \n",
       "59689                 -1.000000                 -1.000000   \n",
       "\n",
       "       TotalClicksVideoConati  ...  TotalClicksWeekend  RatioClicksWeekendDay  \\\n",
       "0                    0.318007  ...             0.17476               0.340702   \n",
       "1                   -1.000000  ...            -1.00000              -1.000000   \n",
       "2                    0.186785  ...             0.17476               0.340702   \n",
       "3                    0.186785  ...             0.17476               0.340702   \n",
       "4                    0.186785  ...             0.17476               0.340702   \n",
       "...                       ...  ...                 ...                    ...   \n",
       "59685               -1.000000  ...            -1.00000              -1.000000   \n",
       "59686               -1.000000  ...            -1.00000              -1.000000   \n",
       "59687               -1.000000  ...            -1.00000              -1.000000   \n",
       "59688               -1.000000  ...            -1.00000              -1.000000   \n",
       "59689               -1.000000  ...            -1.00000              -1.000000   \n",
       "\n",
       "       TotalClicksVideoChen  TotalClicksProblem  TotalTimeProblem  \\\n",
       "0                  0.225483            0.271355          0.179129   \n",
       "1                 -1.000000           -1.000000         -1.000000   \n",
       "2                  0.225483            0.271355          0.163399   \n",
       "3                  0.225483            0.247526          0.163399   \n",
       "4                  0.205682            0.247526          0.179129   \n",
       "...                     ...                 ...               ...   \n",
       "59685             -1.000000           -1.000000         -1.000000   \n",
       "59686             -1.000000           -1.000000         -1.000000   \n",
       "59687             -1.000000           -1.000000         -1.000000   \n",
       "59688             -1.000000           -1.000000         -1.000000   \n",
       "59689             -1.000000           -1.000000         -1.000000   \n",
       "\n",
       "       TotalTimeVideo  CompetencyAlignment  CompetencyAnticipation  \\\n",
       "0            0.179129             0.163398                0.183748   \n",
       "1           -1.000000            -1.000000               -1.000000   \n",
       "2            0.163399             0.179129                0.183748   \n",
       "3            0.179129             0.179129                0.183748   \n",
       "4            0.179129             0.179129                0.183763   \n",
       "...               ...                  ...                     ...   \n",
       "59685       -1.000000            -1.000000               -1.000000   \n",
       "59686       -1.000000            -1.000000               -1.000000   \n",
       "59687       -1.000000            -1.000000               -1.000000   \n",
       "59688       -1.000000            -1.000000               -1.000000   \n",
       "59689       -1.000000            -1.000000               -1.000000   \n",
       "\n",
       "       ContentAlignment  ContentAnticipation  \n",
       "0              0.222652             0.500000  \n",
       "1             -1.000000            -1.000000  \n",
       "2              0.222652             0.567071  \n",
       "3              0.222652             0.500000  \n",
       "4              0.222659             0.362382  \n",
       "...                 ...                  ...  \n",
       "59685         -1.000000            -1.000000  \n",
       "59686         -1.000000            -1.000000  \n",
       "59687         -1.000000            -1.000000  \n",
       "59688         -1.000000            -1.000000  \n",
       "59689         -1.000000            -1.000000  \n",
       "\n",
       "[59690 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = 42\n",
    "num_index = mooc_feat.shape[1] - num_features\n",
    "\n",
    "# Mask df_x values\n",
    "mask = mooc_quizzes.quiz_correct.isna().values\n",
    "mask = np.concatenate([np.zeros((mask.shape[0], num_index), dtype=bool), \n",
    "                       mask[:, None].repeat(num_features, axis=1)], axis=1)\n",
    "df_x = mooc_feat.mask(mask, -1)\n",
    "df_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tlBnu7VJoeho",
   "metadata": {
    "id": "tlBnu7VJoeho"
   },
   "source": [
    "We create `df_y` (the outcome), where we replace NaNs (for quiz_correct) with -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67kEAmPDDJhr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "67kEAmPDDJhr",
    "outputId": "e921d09d-56e4-4d6b-8e5a-1db279c5a353"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-70e969cd-ae3a-417d-b7eb-c39590c5d31d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>week</th>\n",
       "      <th>quiz_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1593</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1593</td>\n",
       "      <td>2</td>\n",
       "      <td>0.807141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1593</td>\n",
       "      <td>3</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1593</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59685</th>\n",
       "      <td>3353959</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59686</th>\n",
       "      <td>3353959</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59687</th>\n",
       "      <td>3353959</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59688</th>\n",
       "      <td>3353959</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59689</th>\n",
       "      <td>3353959</td>\n",
       "      <td>9</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59690 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70e969cd-ae3a-417d-b7eb-c39590c5d31d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-70e969cd-ae3a-417d-b7eb-c39590c5d31d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-70e969cd-ae3a-417d-b7eb-c39590c5d31d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       user_id  week  quiz_correct\n",
       "0         1593     0      0.929825\n",
       "1         1593     1     -1.000000\n",
       "2         1593     2      0.807141\n",
       "3         1593     3      0.960000\n",
       "4         1593     4      0.900000\n",
       "...        ...   ...           ...\n",
       "59685  3353959     5     -1.000000\n",
       "59686  3353959     6     -1.000000\n",
       "59687  3353959     7     -1.000000\n",
       "59688  3353959     8     -1.000000\n",
       "59689  3353959     9     -1.000000\n",
       "\n",
       "[59690 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = mooc_quizzes.fillna(-1)\n",
    "df_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4wvShWLF0Ef",
   "metadata": {
    "id": "c4wvShWLF0Ef"
   },
   "source": [
    "We bring `df_y` and `df_x` to an appropriate shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Rr-moZnw-Lrk",
   "metadata": {
    "id": "Rr-moZnw-Lrk"
   },
   "outputs": [],
   "source": [
    "num_weeks = df_y.week.nunique()\n",
    "df_y = df_y.quiz_correct.values.reshape(-1, num_weeks, 1)\n",
    "df_x = df_x.iloc[:, num_index:].values.reshape(-1, num_weeks, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc044cb-4d28-4a89-9a54-f27def90b0bc",
   "metadata": {
    "id": "cbc044cb-4d28-4a89-9a54-f27def90b0bc",
    "tags": []
   },
   "source": [
    "We then split the data into train, test, and validation data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8KclC5ufblXt",
   "metadata": {
    "id": "8KclC5ufblXt"
   },
   "outputs": [],
   "source": [
    "# Split the MOOC data into training and test sets.\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(\n",
    "                                                        df_x, df_y, test_size=0.2, \n",
    "                                                        random_state=0)\n",
    "\n",
    "# Split the training dataset into validation and training sets.\n",
    "df_x_train_val, df_x_val, df_y_train_val, df_y_val = train_test_split(\n",
    "                                                        df_x_train, df_y_train, \n",
    "                                                        test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GRAUH96UC570",
   "metadata": {
    "id": "GRAUH96UC570"
   },
   "source": [
    "### Tracing: Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c71de6-1bea-4d8d-b273-33418b430a7f",
   "metadata": {
    "id": "a5c71de6-1bea-4d8d-b273-33418b430a7f"
   },
   "source": [
    "Next, we build an LSTM model for predicting student performance on the MOOC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ADS8GgE5CEUi",
   "metadata": {
    "id": "ADS8GgE5CEUi"
   },
   "outputs": [],
   "source": [
    "# We use the default hyperparameters, as described in detail in the DKT model creation section.\n",
    "params = {}\n",
    "params['batch_size'] = 32\n",
    "params['mask_value'] = -1.0\n",
    "params['verbose'] = 1 # Verbose = {0,1,2}\n",
    "params['best_model_weights'] = 'weights/bestmodel' # File to save the model\n",
    "params['optimizer'] = 'adam' # Optimizer to use\n",
    "params['recurrent_units'] = 32 # Number of RNN units\n",
    "params['epochs'] = 20 # Number of epochs to train\n",
    "params['dropout_rate'] = 0.1 # Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7SsVwF5XCZew",
   "metadata": {
    "id": "7SsVwF5XCZew"
   },
   "outputs": [],
   "source": [
    "def create_model_lstm_MOOC(nb_features, nb_skills, params):\n",
    "    \n",
    "    # Create an LSTM model architecture.\n",
    "    inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
    "    \n",
    "    # We use a masking layer here to ignore our masked padding values\n",
    "    x = tf.keras.layers.Masking(mask_value=params['mask_value'])(inputs)\n",
    "\n",
    "    # This LSTM layer is the crux of the model; we use our parameters to specify\n",
    "    # what this layer should look like (# of recurrent_units, fraction of dropout).\n",
    "    x = tf.keras.layers.LSTM(params['recurrent_units'], \n",
    "                             return_sequences=True, \n",
    "                             dropout=params['dropout_rate'])(x)\n",
    "    \n",
    "        \n",
    "    # We use a dense layer with the linear function activation to map our predictions \n",
    "    # on a linear scale. Note that this has changed from a sigmoid activated dense layer\n",
    "    # in the previous LSTM function.\n",
    "    dense = tf.keras.layers.Dense(nb_skills, activation='linear')\n",
    "    outputs = tf.keras.layers.TimeDistributed(dense, name='outputs')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='DKT')\n",
    "\n",
    "    # Compile the model with our loss functions, optimizer, and metrics.\n",
    "    model.compile(loss=tf.keras.losses.MSE, \n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "dkt_lstm = create_model_lstm_MOOC(num_features, 1, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158gxKmhEfhb",
   "metadata": {
    "id": "158gxKmhEfhb"
   },
   "source": [
    "### Tracing: Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5LghGCVBEhtY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5LghGCVBEhtY",
    "outputId": "2d07df52-3bbb-43f3-bd1d-1f31eda99115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 9s 40ms/step - loss: 0.0354 - root_mean_squared_error: 0.3000 - val_loss: 0.0198 - val_root_mean_squared_error: 0.2224\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0193 - root_mean_squared_error: 0.2215 - val_loss: 0.0177 - val_root_mean_squared_error: 0.2103\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0183 - root_mean_squared_error: 0.2156 - val_loss: 0.0174 - val_root_mean_squared_error: 0.2086\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0181 - root_mean_squared_error: 0.2143 - val_loss: 0.0175 - val_root_mean_squared_error: 0.2089\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 4s 29ms/step - loss: 0.0181 - root_mean_squared_error: 0.2145 - val_loss: 0.0171 - val_root_mean_squared_error: 0.2069\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0175 - root_mean_squared_error: 0.2109 - val_loss: 0.0169 - val_root_mean_squared_error: 0.2055\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0174 - root_mean_squared_error: 0.2103 - val_loss: 0.0168 - val_root_mean_squared_error: 0.2052\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0174 - root_mean_squared_error: 0.2105 - val_loss: 0.0168 - val_root_mean_squared_error: 0.2051\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0173 - root_mean_squared_error: 0.2097 - val_loss: 0.0167 - val_root_mean_squared_error: 0.2044\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0172 - root_mean_squared_error: 0.2093 - val_loss: 0.0167 - val_root_mean_squared_error: 0.2043\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0174 - root_mean_squared_error: 0.2101 - val_loss: 0.0167 - val_root_mean_squared_error: 0.2043\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0172 - root_mean_squared_error: 0.2092 - val_loss: 0.0167 - val_root_mean_squared_error: 0.2041\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0172 - root_mean_squared_error: 0.2088 - val_loss: 0.0171 - val_root_mean_squared_error: 0.2067\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0172 - root_mean_squared_error: 0.2087 - val_loss: 0.0166 - val_root_mean_squared_error: 0.2040\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0173 - root_mean_squared_error: 0.2094 - val_loss: 0.0165 - val_root_mean_squared_error: 0.2034\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0172 - root_mean_squared_error: 0.2089 - val_loss: 0.0165 - val_root_mean_squared_error: 0.2033\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0172 - root_mean_squared_error: 0.2089 - val_loss: 0.0165 - val_root_mean_squared_error: 0.2029\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0171 - root_mean_squared_error: 0.2083 - val_loss: 0.0165 - val_root_mean_squared_error: 0.2030\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.0169 - root_mean_squared_error: 0.2069 - val_loss: 0.0163 - val_root_mean_squared_error: 0.2021\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.0168 - root_mean_squared_error: 0.2067 - val_loss: 0.0163 - val_root_mean_squared_error: 0.2018\n"
     ]
    }
   ],
   "source": [
    "# This model takes less than a minute to train on Colab.\n",
    "\n",
    "# We save only the best model during the training process.\n",
    "ckp_callback = tf.keras.callbacks.ModelCheckpoint(params['best_model_weights'], \n",
    "                                                  save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit the DKT LSTM on DSP1 data.\n",
    "history = dkt_lstm.fit(df_x_train_val, df_y_train_val, epochs=params['epochs'],\n",
    "                       validation_data=(df_x_val, df_y_val),\n",
    "                       callbacks=[ckp_callback], verbose=params['verbose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sPd2YM1zZEkS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPd2YM1zZEkS",
    "outputId": "52137c60-afbe-4b18-d2ad-f304396c7f91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0170 - root_mean_squared_error: 0.2037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.0169634148478508, 'root_mean_squared_error': 0.2037271410226822}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best performing model and evaluate the performance.\n",
    "dkt_lstm.load_weights(params['best_model_weights'])\n",
    "dkt_lstm.evaluate(df_x_test, df_y_test, verbose=params['verbose'], return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ijMQ-uFbqA8W",
   "metadata": {
    "id": "ijMQ-uFbqA8W"
   },
   "source": [
    "### Time Series: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db459c-421b-4138-a75c-293a1212cf51",
   "metadata": {
    "id": "98db459c-421b-4138-a75c-293a1212cf51"
   },
   "source": [
    "We now modify our model to predict after `n` weeks, whether students will pass or fail the class. We first load the labels for the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbeb8375-7270-4393-a2ec-5eef816e146f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cbeb8375-7270-4393-a2ec-5eef816e146f",
    "outputId": "51b346a2-586a-4e5b-a69a-4cf12eace331"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-575fc155-0108-4347-ab20-72204b56a4a2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label-pass-fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1593</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1787</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1824</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1836</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-575fc155-0108-4347-ab20-72204b56a4a2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-575fc155-0108-4347-ab20-72204b56a4a2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-575fc155-0108-4347-ab20-72204b56a4a2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   user_id  label-pass-fail\n",
       "0     1593              0.0\n",
       "1     1626              1.0\n",
       "2     1787              1.0\n",
       "3     1824              1.0\n",
       "4     1836              1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mooc_labels = pd.read_csv(DATA_DIR + 'mooc_lab.csv', low_memory=False).dropna()\n",
    "mooc_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288ce05-4d7c-4566-a695-fd6a91de9ed2",
   "metadata": {
    "id": "f288ce05-4d7c-4566-a695-fd6a91de9ed2"
   },
   "source": [
    "We choose `n = 5` weeks and therefore drop all the data from weeks 5 through 10. Since this problem refers to early peformance prediction, we can only train on weeks 1 through 4 of student data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "UDDn8n7DaH0a",
   "metadata": {
    "id": "UDDn8n7DaH0a"
   },
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552f101-a01c-4a69-ae13-78248ad7ba97",
   "metadata": {
    "id": "f552f101-a01c-4a69-ae13-78248ad7ba97"
   },
   "source": [
    "We preprocess our data for this task: \n",
    "\n",
    "- `mooc_labels` should become a NumPy array of size `num_of_students`.\n",
    "\n",
    "- `df_x` should become a NumPy array of size `num_of_students * n * num_of_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2RjEoy0aaKeP",
   "metadata": {
    "id": "2RjEoy0aaKeP"
   },
   "outputs": [],
   "source": [
    "df_x_binary = df_x[:, :n, :]\n",
    "df_y_binary = mooc_labels['label-pass-fail'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b88330-af08-48fb-9587-6fc87cd34cbb",
   "metadata": {
    "id": "43b88330-af08-48fb-9587-6fc87cd34cbb"
   },
   "source": [
    "Finally, we split the data into train/validation/test sets. We do a stratified split (on label-pass-fail) so that the classes are representatively balanced across each of our dataset divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "_AcIVWvbcvbQ",
   "metadata": {
    "id": "_AcIVWvbcvbQ"
   },
   "outputs": [],
   "source": [
    "# Split into training and test sets.\n",
    "df_x_binary_train, df_x_binary_test, df_y_binary_train, df_y_binary_test = train_test_split(\n",
    "                                                                            df_x_binary, \n",
    "                                                                            df_y_binary,\n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=0, \n",
    "                                                                            stratify=df_y_binary)\n",
    "\n",
    "# Split training into training and validation sets.\n",
    "df_x_binary_train_val, df_x_binary_val, df_y_binary_train_val, df_y_binary_val = train_test_split(\n",
    "                                                                            df_x_binary_train, \n",
    "                                                                            df_y_binary_train, \n",
    "                                                                            test_size=0.2,\n",
    "                                                                            random_state=0, \n",
    "                                                                            stratify=df_y_binary_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d967a-9039-4b08-9106-b24b6ba15cc8",
   "metadata": {
    "id": "013d967a-9039-4b08-9106-b24b6ba15cc8"
   },
   "source": [
    "### Time Series: Model Creation\n",
    "\n",
    "Now, we can again create an lstm model, which takes the features up to week 5 as an input and predicts the pass/fail label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a-kJWnIidQgW",
   "metadata": {
    "id": "a-kJWnIidQgW"
   },
   "outputs": [],
   "source": [
    "def create_model_lstm_mooc_binary(nb_features, nb_skills, params):\n",
    "    \n",
    "    # Create an LSTM model architecture.\n",
    "    inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
    "    \n",
    "    # We use a masking layer here to ignore our masked padding values\n",
    "    x = tf.keras.layers.Masking(mask_value=params['mask_value'])(inputs)\n",
    "\n",
    "    # This LSTM layer is the crux of the model; we use our parameters to specify\n",
    "    # what this layer should look like (# of recurrent_units, fraction of dropout).\n",
    "    # Note that return_sequences=False because we want a many-to-one architecture.\n",
    "    x = tf.keras.layers.LSTM(params['recurrent_units'], \n",
    "                             return_sequences=False, \n",
    "                             dropout=params['dropout_rate'])(x)\n",
    "    \n",
    "        \n",
    "    # We use a dense layer with the sigmoid function activation to map our predictions \n",
    "    # between 0 and 1.\n",
    "    dense = tf.keras.layers.Dense(nb_skills, activation='sigmoid')\n",
    "    outputs = dense(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='TimeSeries')\n",
    "\n",
    "    # Compile the model with our loss functions, optimizer, and metrics.\n",
    "    model.compile(loss=tf.keras.losses.binary_crossentropy, \n",
    "                  optimizer=params['optimizer'],\n",
    "                  metrics=[tf.keras.metrics.AUC(), 'binary_accuracy'])    \n",
    "    return model\n",
    "\n",
    "time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fEaSNCn_1d91",
   "metadata": {
    "id": "fEaSNCn_1d91"
   },
   "source": [
    "### Time Series: Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rgwXrLNnen4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgwXrLNnen4c",
    "outputId": "bbe4456f-6d32-47f0-b19e-62a0b12e9d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 15s 38ms/step - loss: 0.4403 - auc: 0.8889 - binary_accuracy: 0.8301 - val_loss: 0.2412 - val_auc: 0.9552 - val_binary_accuracy: 0.9068\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2376 - auc: 0.9478 - binary_accuracy: 0.8984 - val_loss: 0.2206 - val_auc: 0.9630 - val_binary_accuracy: 0.9005\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2248 - auc: 0.9513 - binary_accuracy: 0.9068 - val_loss: 0.2094 - val_auc: 0.9683 - val_binary_accuracy: 0.9141\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2202 - auc: 0.9534 - binary_accuracy: 0.9079 - val_loss: 0.2093 - val_auc: 0.9693 - val_binary_accuracy: 0.9162\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2134 - auc: 0.9581 - binary_accuracy: 0.9105 - val_loss: 0.2001 - val_auc: 0.9705 - val_binary_accuracy: 0.9330\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2079 - auc: 0.9606 - binary_accuracy: 0.9165 - val_loss: 0.1972 - val_auc: 0.9711 - val_binary_accuracy: 0.9267\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2019 - auc: 0.9631 - binary_accuracy: 0.9170 - val_loss: 0.1906 - val_auc: 0.9712 - val_binary_accuracy: 0.9246\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1986 - auc: 0.9657 - binary_accuracy: 0.9183 - val_loss: 0.1832 - val_auc: 0.9728 - val_binary_accuracy: 0.9298\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 7s 57ms/step - loss: 0.1921 - auc: 0.9681 - binary_accuracy: 0.9204 - val_loss: 0.1803 - val_auc: 0.9754 - val_binary_accuracy: 0.9267\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.1883 - auc: 0.9700 - binary_accuracy: 0.9215 - val_loss: 0.1764 - val_auc: 0.9769 - val_binary_accuracy: 0.9288\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 7s 55ms/step - loss: 0.1888 - auc: 0.9698 - binary_accuracy: 0.9236 - val_loss: 0.1710 - val_auc: 0.9789 - val_binary_accuracy: 0.9340\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.1811 - auc: 0.9730 - binary_accuracy: 0.9249 - val_loss: 0.1684 - val_auc: 0.9793 - val_binary_accuracy: 0.9330\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1821 - auc: 0.9711 - binary_accuracy: 0.9257 - val_loss: 0.1676 - val_auc: 0.9789 - val_binary_accuracy: 0.9351\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1805 - auc: 0.9725 - binary_accuracy: 0.9288 - val_loss: 0.1690 - val_auc: 0.9768 - val_binary_accuracy: 0.9298\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1825 - auc: 0.9723 - binary_accuracy: 0.9296 - val_loss: 0.1654 - val_auc: 0.9802 - val_binary_accuracy: 0.9351\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1744 - auc: 0.9735 - binary_accuracy: 0.9317 - val_loss: 0.1624 - val_auc: 0.9798 - val_binary_accuracy: 0.9340\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1807 - auc: 0.9719 - binary_accuracy: 0.9296 - val_loss: 0.1617 - val_auc: 0.9803 - val_binary_accuracy: 0.9351\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1782 - auc: 0.9738 - binary_accuracy: 0.9288 - val_loss: 0.1639 - val_auc: 0.9797 - val_binary_accuracy: 0.9414\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1765 - auc: 0.9735 - binary_accuracy: 0.9296 - val_loss: 0.1622 - val_auc: 0.9802 - val_binary_accuracy: 0.9351\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1781 - auc: 0.9729 - binary_accuracy: 0.9296 - val_loss: 0.1600 - val_auc: 0.9811 - val_binary_accuracy: 0.9361\n"
     ]
    }
   ],
   "source": [
    "# This model should take ~30 seconds to train on CoLab.\n",
    "\n",
    "# We save only the best model during the training process.\n",
    "ckp_callback = tf.keras.callbacks.ModelCheckpoint(params['best_model_weights'], \n",
    "                                                  save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Fit the DKT LSTM on DSP1 data.\n",
    "history = time_series_lstm.fit(df_x_binary_train_val, \n",
    "                               df_y_binary_train_val, \n",
    "                               epochs=params['epochs'],\n",
    "                               validation_data=(df_x_binary_val, df_y_binary_val),\n",
    "                               callbacks=[ckp_callback], \n",
    "                               verbose=params['verbose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb531ec-c702-4bab-bf3d-571110857bb7",
   "metadata": {
    "id": "5fb531ec-c702-4bab-bf3d-571110857bb7"
   },
   "source": [
    "To evaluate performance of the model, we can also use `predict` instead of `evaluate` to get the actual predictions of the model. We can then compute any evaluation metric based on the true labels and the model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "O03_Uk_KemAA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O03_Uk_KemAA",
    "outputId": "9d033741-7acb-439a-a012-27d392c5804a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy:  0.9340443384561032\n",
      "AUC:  0.9773707531060473\n"
     ]
    }
   ],
   "source": [
    "# Load the best version of the the trained model and evaluate its performance on the test_set.\n",
    "time_series_lstm.load_weights(params['best_model_weights'])\n",
    "predictions = time_series_lstm.predict(df_x_binary_test)\n",
    "bac = balanced_accuracy_score(df_y_binary_test, predictions>0.5)\n",
    "auc = roc_auc_score(df_y_binary_test,predictions)\n",
    "print(\"Balanced accuracy: \", bac)\n",
    "print(\"AUC: \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3lI5N75Zrobn",
   "metadata": {
    "id": "3lI5N75Zrobn"
   },
   "source": [
    "### Time Series: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2NLKnbRzf_P0",
   "metadata": {
    "id": "2NLKnbRzf_P0"
   },
   "outputs": [],
   "source": [
    "# Modify the dictionary of parameters so that each parameter maps to a list of possibilities.\n",
    "# In this case, we're only searching over the recurrent_units and leaving the rest of the \n",
    "# parameters fixed to their default values.\n",
    "params_space = {param: [value] for param, value in params.items()}\n",
    "params_space['recurrent_units'] = [8, 16, 32, 64]\n",
    "params_grid = ParameterGrid(params_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "h1aEPNQTgEdI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1aEPNQTgEdI",
    "outputId": "e3e62537-4c89-4c65-9070-3ab38f40013f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 9s 35ms/step - loss: 0.5112 - auc_1: 0.8638 - binary_accuracy: 0.8058 - val_loss: 0.3311 - val_auc_1: 0.9676 - val_binary_accuracy: 0.9183\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2867 - auc_1: 0.9509 - binary_accuracy: 0.9034 - val_loss: 0.2450 - val_auc_1: 0.9646 - val_binary_accuracy: 0.8995\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2481 - auc_1: 0.9520 - binary_accuracy: 0.9073 - val_loss: 0.2288 - val_auc_1: 0.9665 - val_binary_accuracy: 0.8974\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2344 - auc_1: 0.9551 - binary_accuracy: 0.9034 - val_loss: 0.2140 - val_auc_1: 0.9701 - val_binary_accuracy: 0.9267\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2308 - auc_1: 0.9545 - binary_accuracy: 0.9081 - val_loss: 0.2075 - val_auc_1: 0.9715 - val_binary_accuracy: 0.9340\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.2222 - auc_1: 0.9573 - binary_accuracy: 0.9139 - val_loss: 0.2018 - val_auc_1: 0.9718 - val_binary_accuracy: 0.9361\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2174 - auc_1: 0.9593 - binary_accuracy: 0.9139 - val_loss: 0.1989 - val_auc_1: 0.9729 - val_binary_accuracy: 0.9277\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2106 - auc_1: 0.9608 - binary_accuracy: 0.9178 - val_loss: 0.1948 - val_auc_1: 0.9725 - val_binary_accuracy: 0.9236\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2060 - auc_1: 0.9623 - binary_accuracy: 0.9131 - val_loss: 0.1886 - val_auc_1: 0.9730 - val_binary_accuracy: 0.9351\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2039 - auc_1: 0.9637 - binary_accuracy: 0.9173 - val_loss: 0.1857 - val_auc_1: 0.9746 - val_binary_accuracy: 0.9351\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1996 - auc_1: 0.9661 - binary_accuracy: 0.9204 - val_loss: 0.1837 - val_auc_1: 0.9735 - val_binary_accuracy: 0.9288\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2007 - auc_1: 0.9649 - binary_accuracy: 0.9181 - val_loss: 0.1798 - val_auc_1: 0.9751 - val_binary_accuracy: 0.9330\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.1924 - auc_1: 0.9682 - binary_accuracy: 0.9249 - val_loss: 0.1758 - val_auc_1: 0.9762 - val_binary_accuracy: 0.9351\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1955 - auc_1: 0.9668 - binary_accuracy: 0.9194 - val_loss: 0.1746 - val_auc_1: 0.9766 - val_binary_accuracy: 0.9340\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1934 - auc_1: 0.9667 - binary_accuracy: 0.9225 - val_loss: 0.1747 - val_auc_1: 0.9778 - val_binary_accuracy: 0.9340\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1908 - auc_1: 0.9690 - binary_accuracy: 0.9202 - val_loss: 0.1737 - val_auc_1: 0.9781 - val_binary_accuracy: 0.9298\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1903 - auc_1: 0.9685 - binary_accuracy: 0.9233 - val_loss: 0.1709 - val_auc_1: 0.9788 - val_binary_accuracy: 0.9351\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1893 - auc_1: 0.9698 - binary_accuracy: 0.9199 - val_loss: 0.1714 - val_auc_1: 0.9798 - val_binary_accuracy: 0.9309\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1871 - auc_1: 0.9701 - binary_accuracy: 0.9220 - val_loss: 0.1666 - val_auc_1: 0.9800 - val_binary_accuracy: 0.9340\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1897 - auc_1: 0.9687 - binary_accuracy: 0.9228 - val_loss: 0.1666 - val_auc_1: 0.9799 - val_binary_accuracy: 0.9361\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.1666 - auc_1: 0.9799 - binary_accuracy: 0.9361\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 11s 48ms/step - loss: 0.5435 - auc_2: 0.7280 - binary_accuracy: 0.7691 - val_loss: 0.3162 - val_auc_2: 0.9618 - val_binary_accuracy: 0.9089\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2630 - auc_2: 0.9431 - binary_accuracy: 0.9047 - val_loss: 0.2271 - val_auc_2: 0.9642 - val_binary_accuracy: 0.9110\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2331 - auc_2: 0.9506 - binary_accuracy: 0.9000 - val_loss: 0.2128 - val_auc_2: 0.9671 - val_binary_accuracy: 0.9141\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2229 - auc_2: 0.9551 - binary_accuracy: 0.9052 - val_loss: 0.2111 - val_auc_2: 0.9684 - val_binary_accuracy: 0.9204\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.2170 - auc_2: 0.9571 - binary_accuracy: 0.9102 - val_loss: 0.2068 - val_auc_2: 0.9692 - val_binary_accuracy: 0.9173\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2130 - auc_2: 0.9588 - binary_accuracy: 0.9102 - val_loss: 0.1952 - val_auc_2: 0.9716 - val_binary_accuracy: 0.9309\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.2094 - auc_2: 0.9603 - binary_accuracy: 0.9134 - val_loss: 0.1904 - val_auc_2: 0.9729 - val_binary_accuracy: 0.9204\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 6s 52ms/step - loss: 0.2023 - auc_2: 0.9649 - binary_accuracy: 0.9144 - val_loss: 0.1863 - val_auc_2: 0.9733 - val_binary_accuracy: 0.9319\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.1984 - auc_2: 0.9650 - binary_accuracy: 0.9183 - val_loss: 0.1815 - val_auc_2: 0.9751 - val_binary_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.1963 - auc_2: 0.9665 - binary_accuracy: 0.9194 - val_loss: 0.1802 - val_auc_2: 0.9737 - val_binary_accuracy: 0.9267\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 6s 51ms/step - loss: 0.1940 - auc_2: 0.9670 - binary_accuracy: 0.9183 - val_loss: 0.1737 - val_auc_2: 0.9752 - val_binary_accuracy: 0.9340\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1930 - auc_2: 0.9673 - binary_accuracy: 0.9215 - val_loss: 0.1730 - val_auc_2: 0.9756 - val_binary_accuracy: 0.9351\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1897 - auc_2: 0.9690 - binary_accuracy: 0.9207 - val_loss: 0.1700 - val_auc_2: 0.9765 - val_binary_accuracy: 0.9351\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1871 - auc_2: 0.9690 - binary_accuracy: 0.9225 - val_loss: 0.1693 - val_auc_2: 0.9772 - val_binary_accuracy: 0.9361\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1843 - auc_2: 0.9710 - binary_accuracy: 0.9270 - val_loss: 0.1661 - val_auc_2: 0.9770 - val_binary_accuracy: 0.9309\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1780 - auc_2: 0.9736 - binary_accuracy: 0.9285 - val_loss: 0.1636 - val_auc_2: 0.9783 - val_binary_accuracy: 0.9361\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1810 - auc_2: 0.9729 - binary_accuracy: 0.9277 - val_loss: 0.1661 - val_auc_2: 0.9785 - val_binary_accuracy: 0.9372\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1821 - auc_2: 0.9715 - binary_accuracy: 0.9262 - val_loss: 0.1642 - val_auc_2: 0.9784 - val_binary_accuracy: 0.9340\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1773 - auc_2: 0.9733 - binary_accuracy: 0.9322 - val_loss: 0.1680 - val_auc_2: 0.9779 - val_binary_accuracy: 0.9372\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1821 - auc_2: 0.9714 - binary_accuracy: 0.9246 - val_loss: 0.1609 - val_auc_2: 0.9789 - val_binary_accuracy: 0.9330\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1609 - auc_2: 0.9789 - binary_accuracy: 0.9330\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 9s 37ms/step - loss: 0.4512 - auc_3: 0.8714 - binary_accuracy: 0.8390 - val_loss: 0.2531 - val_auc_3: 0.9522 - val_binary_accuracy: 0.8942\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2467 - auc_3: 0.9464 - binary_accuracy: 0.9005 - val_loss: 0.2219 - val_auc_3: 0.9624 - val_binary_accuracy: 0.9351\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2281 - auc_3: 0.9504 - binary_accuracy: 0.9047 - val_loss: 0.2143 - val_auc_3: 0.9677 - val_binary_accuracy: 0.9309\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2219 - auc_3: 0.9534 - binary_accuracy: 0.9045 - val_loss: 0.2172 - val_auc_3: 0.9682 - val_binary_accuracy: 0.8942\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.2158 - auc_3: 0.9558 - binary_accuracy: 0.9118 - val_loss: 0.2049 - val_auc_3: 0.9711 - val_binary_accuracy: 0.9225\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2099 - auc_3: 0.9591 - binary_accuracy: 0.9141 - val_loss: 0.1928 - val_auc_3: 0.9729 - val_binary_accuracy: 0.9162\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2094 - auc_3: 0.9600 - binary_accuracy: 0.9084 - val_loss: 0.1874 - val_auc_3: 0.9733 - val_binary_accuracy: 0.9361\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1998 - auc_3: 0.9641 - binary_accuracy: 0.9186 - val_loss: 0.1878 - val_auc_3: 0.9721 - val_binary_accuracy: 0.9257\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1952 - auc_3: 0.9667 - binary_accuracy: 0.9183 - val_loss: 0.1860 - val_auc_3: 0.9767 - val_binary_accuracy: 0.9288\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1868 - auc_3: 0.9706 - binary_accuracy: 0.9217 - val_loss: 0.1749 - val_auc_3: 0.9761 - val_binary_accuracy: 0.9309\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1890 - auc_3: 0.9698 - binary_accuracy: 0.9223 - val_loss: 0.1705 - val_auc_3: 0.9780 - val_binary_accuracy: 0.9330\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1851 - auc_3: 0.9707 - binary_accuracy: 0.9275 - val_loss: 0.1703 - val_auc_3: 0.9779 - val_binary_accuracy: 0.9288\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1848 - auc_3: 0.9709 - binary_accuracy: 0.9257 - val_loss: 0.1669 - val_auc_3: 0.9797 - val_binary_accuracy: 0.9340\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1846 - auc_3: 0.9704 - binary_accuracy: 0.9249 - val_loss: 0.1656 - val_auc_3: 0.9798 - val_binary_accuracy: 0.9351\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1810 - auc_3: 0.9723 - binary_accuracy: 0.9298 - val_loss: 0.1645 - val_auc_3: 0.9795 - val_binary_accuracy: 0.9330\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1825 - auc_3: 0.9713 - binary_accuracy: 0.9249 - val_loss: 0.1633 - val_auc_3: 0.9803 - val_binary_accuracy: 0.9361\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1762 - auc_3: 0.9738 - binary_accuracy: 0.9309 - val_loss: 0.1661 - val_auc_3: 0.9799 - val_binary_accuracy: 0.9340\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1779 - auc_3: 0.9726 - binary_accuracy: 0.9272 - val_loss: 0.1623 - val_auc_3: 0.9802 - val_binary_accuracy: 0.9319\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1799 - auc_3: 0.9725 - binary_accuracy: 0.9301 - val_loss: 0.1655 - val_auc_3: 0.9800 - val_binary_accuracy: 0.9351\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.1713 - auc_3: 0.9757 - binary_accuracy: 0.9301 - val_loss: 0.1592 - val_auc_3: 0.9804 - val_binary_accuracy: 0.9424\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1592 - auc_3: 0.9804 - binary_accuracy: 0.9424\n",
      "Epoch 1/20\n",
      "120/120 [==============================] - 9s 37ms/step - loss: 0.3917 - auc_4: 0.9005 - binary_accuracy: 0.8385 - val_loss: 0.2269 - val_auc_4: 0.9573 - val_binary_accuracy: 0.9131\n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.2314 - auc_4: 0.9474 - binary_accuracy: 0.9039 - val_loss: 0.2191 - val_auc_4: 0.9672 - val_binary_accuracy: 0.9236\n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2234 - auc_4: 0.9510 - binary_accuracy: 0.9079 - val_loss: 0.2085 - val_auc_4: 0.9704 - val_binary_accuracy: 0.9330\n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2161 - auc_4: 0.9560 - binary_accuracy: 0.9068 - val_loss: 0.1999 - val_auc_4: 0.9705 - val_binary_accuracy: 0.9141\n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.2103 - auc_4: 0.9582 - binary_accuracy: 0.9141 - val_loss: 0.1925 - val_auc_4: 0.9739 - val_binary_accuracy: 0.9351\n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1987 - auc_4: 0.9654 - binary_accuracy: 0.9188 - val_loss: 0.1862 - val_auc_4: 0.9738 - val_binary_accuracy: 0.9277\n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1967 - auc_4: 0.9668 - binary_accuracy: 0.9194 - val_loss: 0.1784 - val_auc_4: 0.9774 - val_binary_accuracy: 0.9319\n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1891 - auc_4: 0.9698 - binary_accuracy: 0.9215 - val_loss: 0.1773 - val_auc_4: 0.9786 - val_binary_accuracy: 0.9309\n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1884 - auc_4: 0.9699 - binary_accuracy: 0.9191 - val_loss: 0.1743 - val_auc_4: 0.9770 - val_binary_accuracy: 0.9288\n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1848 - auc_4: 0.9720 - binary_accuracy: 0.9291 - val_loss: 0.1700 - val_auc_4: 0.9788 - val_binary_accuracy: 0.9340\n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1820 - auc_4: 0.9710 - binary_accuracy: 0.9288 - val_loss: 0.1676 - val_auc_4: 0.9785 - val_binary_accuracy: 0.9340\n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1832 - auc_4: 0.9722 - binary_accuracy: 0.9241 - val_loss: 0.1879 - val_auc_4: 0.9789 - val_binary_accuracy: 0.9319\n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1851 - auc_4: 0.9696 - binary_accuracy: 0.9262 - val_loss: 0.1685 - val_auc_4: 0.9789 - val_binary_accuracy: 0.9393\n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1756 - auc_4: 0.9745 - binary_accuracy: 0.9285 - val_loss: 0.1643 - val_auc_4: 0.9783 - val_binary_accuracy: 0.9414\n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1835 - auc_4: 0.9720 - binary_accuracy: 0.9270 - val_loss: 0.1700 - val_auc_4: 0.9775 - val_binary_accuracy: 0.9372\n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.1794 - auc_4: 0.9735 - binary_accuracy: 0.9262 - val_loss: 0.1686 - val_auc_4: 0.9768 - val_binary_accuracy: 0.9309\n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 3s 22ms/step - loss: 0.1806 - auc_4: 0.9722 - binary_accuracy: 0.9249 - val_loss: 0.1620 - val_auc_4: 0.9785 - val_binary_accuracy: 0.9372\n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 3s 23ms/step - loss: 0.1722 - auc_4: 0.9756 - binary_accuracy: 0.9317 - val_loss: 0.1619 - val_auc_4: 0.9792 - val_binary_accuracy: 0.9372\n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.1704 - auc_4: 0.9757 - binary_accuracy: 0.9335 - val_loss: 0.1597 - val_auc_4: 0.9786 - val_binary_accuracy: 0.9361\n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.1783 - auc_4: 0.9734 - binary_accuracy: 0.9238 - val_loss: 0.1596 - val_auc_4: 0.9785 - val_binary_accuracy: 0.9382\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1596 - auc_4: 0.9785 - binary_accuracy: 0.9382\n"
     ]
    }
   ],
   "source": [
    "# Conduct the gridsearch over hyperparameters.\n",
    "# This cell should take ~3 minutes to run.\n",
    "results = {}\n",
    "\n",
    "# For each parameter setting in the grid search of parameters\n",
    "for params_i in params_grid:\n",
    "\n",
    "    # Create a LSTM model with the specific parameter setting params_i\n",
    "    time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params_i)\n",
    "\n",
    "    save_model_name = params_i['best_model_weights'] + str(params_i['recurrent_units'])\n",
    "\n",
    "    # Save the best version of the model through the training epochs\n",
    "    ckp_callback = tf.keras.callbacks.ModelCheckpoint(save_model_name, \n",
    "                                                      save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    # Fit the model on the training data with the appropriate parameters  \n",
    "    time_series_lstm.fit(df_x_binary_train_val, \n",
    "                         df_y_binary_train_val, \n",
    "                         epochs=params_i['epochs'],\n",
    "                         validation_data=(df_x_binary_val, df_y_binary_val),\n",
    "                         callbacks=[ckp_callback], \n",
    "                         verbose=params_i['verbose'])\n",
    "\n",
    "    # Evaluate the model performance\n",
    "    results[params_i['recurrent_units']] = time_series_lstm.evaluate(df_x_binary_val, \n",
    "                                                                     df_y_binary_val,\n",
    "                                                                     verbose=params_i['verbose'], \n",
    "                                                                     return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "NgrodvSKgHvT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NgrodvSKgHvT",
    "outputId": "37f9a20e-4c46-4dbe-9a44-fcd3e352ab9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort candidate parameters according to their accuracy\n",
    "results = sorted(results.items(), key=lambda x: x[1]['binary_accuracy'], reverse=True)\n",
    "\n",
    "# Obtain the best parameters\n",
    "best_params = results[0][0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "g_Tkk2kjgU_L",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_Tkk2kjgU_L",
    "outputId": "ea5832b5-6b75-4b17-d14e-9ed14560d6cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy:  0.941651210033563\n",
      "AUC:  0.9775768415474297\n"
     ]
    }
   ],
   "source": [
    "# Load the best model variant from the hyperparameter gridsearch\n",
    "params['recurrent_units'] = best_params\n",
    "time_series_lstm = create_model_lstm_mooc_binary(num_features, 1, params)\n",
    "time_series_lstm.load_weights(params['best_model_weights'] + str(best_params))\n",
    "\n",
    "predictions = time_series_lstm.predict(df_x_binary_test)\n",
    "bac = balanced_accuracy_score(df_y_binary_test, predictions>0.5)\n",
    "auc = roc_auc_score(df_y_binary_test,predictions)\n",
    "print(\"Balanced accuracy: \", bac)\n",
    "print(\"AUC: \", auc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "08-demo-version.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
