{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8135284-1238-480e-89d8-5790b142ea66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 8 - DKT Model Comparison"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "494fe36e-c815-4bae-88b4-6c784e829d1d",
   "metadata": {},
   "source": [
    "In this exercises, you will compare the performance of different knowledge tracing models. We will use the same ASSISTments data set as in week 7.\n",
    "\n",
    "The ASSISTments data sets are often used for benchmarking knowledge tracing models. We will play with a simplified data set that contains the following columns:\n",
    "\n",
    "| Name                   | Description                         |\n",
    "| ---------------------- | ------------------------------------------------------------ |\n",
    "| user_id | The ID of the student who is solving the problem.  | |\n",
    "| order_id | The temporal ID (timestamp) associated with the student's answer to the problem.  | |\n",
    "| skill_name | The name of the skill associated with the problem. | |\n",
    "| correct | The student's performance on the problem: 1 if the problem's answer is correct at the first attempt, 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afa5c3-2017-4e04-8513-c2735ebe27ed",
   "metadata": {},
   "source": [
    "Note that this notebook will need to use the tensorflow kernel. Change the kernel in the upper right corner of Noto. Select `tensorflow`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f92b49-a6b7-481e-abe3-8bd1d929965f",
   "metadata": {},
   "source": [
    "We first load the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3cc5d-dfdc-4214-b01c-0f9b8dfa77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal package imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "\n",
    "# Scikit-learn package imports\n",
    "from sklearn import feature_extraction, model_selection\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "# PyBKT package imports\n",
    "from pyBKT.models import Model\n",
    "# Import the lmm model class\n",
    "from pymer4.models import Lmer\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_DIR = \"./../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e03b6b-462f-4770-af1c-c0b4fd00f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistments = pd.read_csv(DATA_DIR + 'assistments.csv', low_memory=False).dropna()\n",
    "assistments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462477a1-47f4-4610-b41e-569cf320903f",
   "metadata": {},
   "source": [
    "Next, we print the number of unique students and skills in this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8bfc64-ddd6-48b7-9a05-5a5453e5f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique students in the dataset:\", len(set(assistments['user_id'])))\n",
    "print(\"Number of unique skills in the dataset:\", len(set(assistments['skill_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b13c9b-53d6-4a23-9496-5d41798d1dc7",
   "metadata": {},
   "source": [
    "We also implement a utility function that splits the data in two folds, making sure that all interactions of a student land in the same fold. We will use this function to obtain train, test, and validation folds of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea098b-23ab-467f-981d-80b28f97dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_iterator(data):\n",
    "    '''\n",
    "    Create an iterator to split interactions in data into train and test, with the same student not appearing in two diverse folds.\n",
    "    :param data:        Dataframe with student's interactions.\n",
    "    :return:            An iterator.\n",
    "    '''    \n",
    "    # Both passing a matrix with the raw data or just an array of indexes works\n",
    "    X = np.arange(len(data.index)) \n",
    "    # Groups of interactions are identified by the user id (we do not want the same user appearing in two folds)\n",
    "    groups = data['user_id'].values \n",
    "    return model_selection.GroupShuffleSplit(n_splits=1, train_size=.8, test_size=0.2, random_state=0).split(X, groups=groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca629369-e82e-4f59-a086-d07c3e63351c",
   "metadata": {},
   "source": [
    "## Additive Factors Model (AFM) and Performance Factors Analysis (PFA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340908f-22c1-4e1f-a631-ff12be331ec0",
   "metadata": {},
   "source": [
    "The AFM and PFA models are both based on logistic regression and item response theory (IRT). Specifically, they compute the probability that a student will solve a task correctly based on the number of previous attempts the student had at the corresponding skill (in case of AFM) and based on the correct and wrong attempts at the corresponding skill (in case of PFA), respectively. We therefore first preprocess the data to compute these variables. For demonstration purposes, we will continue on the small subset of the data set containing six skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a0e39-7f88-47c4-8c6d-5ab84af3892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_subset = ['Circle Graph', 'Venn Diagram', 'Mode', 'Division Fractions', 'Finding Percents', 'Area Rectangle']\n",
    "data = assistments[assistments['skill_name'].isin(skills_subset)]\n",
    "\n",
    "print(\"Skill set:\", set(data['skill_name']))\n",
    "print(\"Number of unique students in the subset:\", len(set(data['user_id'])))\n",
    "print(\"Number of unique skills in the subset:\", len(set(data['skill_name'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a25b8d-1acb-4d7c-bc44-45319a193a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "# Number of attempts before current\n",
    "def preprocess_data(data):\n",
    "    data.loc[:, 'aux'] = 1\n",
    "    data.loc[:, 'prev_attempts'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['aux'].cumsum() -1\n",
    "\n",
    "    # Number of correct and incorrect attempts before current attempt\n",
    "    data.loc[:, 'correct_aux'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['correct'].cumsum()\n",
    "    data.loc[:, 'before_correct_num'] = data.sort_values('order_id').groupby(['user_id', 'skill_name'])['correct_aux'].shift(periods=1, fill_value=0)\n",
    "    data.loc[:, 'before_wrong_num'] = data['prev_attempts'] - data['before_correct_num']\n",
    "    return data\n",
    "\n",
    "data = preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1ebc58-9d11-4aae-bd8c-bd514c8d8ded",
   "metadata": {},
   "source": [
    "Next, we split the data into a training and a test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c1ff6-e1c0-406a-ada9-c9408a88a38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain indexes\n",
    "train_index, test_index = next(create_iterator(data))\n",
    "# Split the data\n",
    "X_train, X_test = data.iloc[train_index], data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c9fe3-b53b-4d4e-ab63-42ed014062c2",
   "metadata": {},
   "source": [
    "Next, we fit an AFM model to the training data and predict on the test data. Note that the implementation below only works for a one-to-one correspondance of task and skill, i.e. when a task is associated to exactly one skill. In case of a data set containing tasks with multiple skills, we would need to use the [pyAFM](https://github.com/cmaclell/pyAFM) package. A tutorial on using pyAFM can be found [here](https://github.com/epfl-ml4ed/mlbd-2021/tree/main/Tutorials/Tutorial06/Tutorial06)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc29981-4a6d-4678-9a4c-f9dca55432c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "model = Lmer(\"correct ~ (1|user_id) + (1|skill_name) + (0 + prev_attempts|skill_name)\", data=X_train, family='binomial')\n",
    "%time model.fit() \n",
    "# Compute predictions\n",
    "X_test['afm_predictions'] = model.predict(data=X_test, verify_predictions=False)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857fc582-3635-4177-9570-d6ac55af27df",
   "metadata": {},
   "source": [
    "Next, we fit a PFA model to the data. Again, this implementation works for one-to-one correspondance and tasks with multiple skills would require the use of [pyAFM](https://github.com/cmaclell/pyAFM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b111e-0433-4abe-a717-34149538b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "model = Lmer(\"correct ~ (1|user_id) + (1|skill_name) + (0 + before_correct_num|skill_name) + (0 + before_wrong_num|skill_name)\", data=X_train, family='binomial')\n",
    "%time model.fit() \n",
    "# Compute predictions\n",
    "X_test['pfa_predictions'] = model.predict(data=X_test, verify_predictions=False)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3170fc-04a0-4270-939b-c0a44d602bed",
   "metadata": {},
   "source": [
    "## Deep Knowledge Tracing (DKT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b566d0-bda1-4a92-943b-5403d16ea291",
   "metadata": {},
   "source": [
    "Knowledge tracing is one of the key research areas for empowering personalized education. It is a task to model students' mastery level of a skill based on their historical learning trajectories. In recent years, a recurrent neural network model called deep knowledge tracing (DKT) has been proposed to handle the knowledge tracing task and literature has shown that DKT generally outperforms traditional methods.\n",
    "\n",
    "Next, we will create and evaluate DKT models on top of a TensorFlow framework. For those who are not familiar with this framework, we recommended to follow the [official tutorials](https://www.tensorflow.org/tutorials/quickstart/beginner). \n",
    "\n",
    "We continue to work with the small subset (six skills of the data). Furthermore, we will continue to use the same train test split as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cd3fec-1836-45f9-8d6d-3bfe6722c31e",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "A DKT model is characterized by the following main three components:\n",
    "- **Input**: the one-hot encoded observations at varying time steps. \n",
    "- **Network**: a recurrent neural network that processes the one-hot encoded observations in a time-wise manner. \n",
    "- **Output**: the probabilities for answering skill (or item) correct at the varying time steps.  \n",
    "\n",
    "The first step to enable a DKT experimental pipeline requires to prepare the input and output data to be fed into the model during the training and evaluation phases. TensorFlow has an API, called [TF Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), that supports writing descriptive and efficient input pipelines. Dataset usage follows a common pattern: (i) create a source dataset from your input data, (ii) apply dataset transformations to preprocess the data, (iii) iterate over the dataset and process the elements. Iteration happens in a streaming fashion, so the full dataset does not need to fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cdd7c1-648b-4d48-9f11-a154bc1b968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_seq(df):\n",
    "    # Step 1 - Enumerate skill id\n",
    "    df['skill'], skill_codes = pd.factorize(df['skill_name'], sort=True)\n",
    "\n",
    "    # Step 2 - Cross skill id with answer to form a synthetic feature\n",
    "    df['skill_with_answer'] = df['skill'] * 2 + df['correct']\n",
    "\n",
    "    # Step 3 - Convert to a sequence per user id and shift features 1 timestep\n",
    "    seq = df.groupby('user_id').apply(lambda r: (r['skill_with_answer'].values[:-1], r['skill'].values[1:], r['correct'].values[1:],))\n",
    "    \n",
    "    # Step 4- Get max skill depth and max feature depth\n",
    "    skill_depth = df['skill'].max() \n",
    "    features_depth = df['skill_with_answer'].max() + 1\n",
    "\n",
    "    return seq, features_depth, skill_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5af72e-0a26-448d-91dc-a2baa983973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(seq, params, features_depth, skill_depth):\n",
    "    \n",
    "    # Step 1 - Get Tensorflow Dataset\n",
    "    dataset = tf.data.Dataset.from_generator(generator=lambda: seq, output_types=(tf.int32, tf.int32, tf.float32))\n",
    "\n",
    "    # Step 2 - Encode categorical features and merge skills with labels to compute target loss.\n",
    "    dataset = dataset.map(\n",
    "        lambda feat, skill, label: (\n",
    "            tf.one_hot(feat, depth=features_depth),\n",
    "            tf.concat(values=[tf.one_hot(skill, depth=skill_depth), tf.expand_dims(label, -1)], axis=-1)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Step 3 - Pad sequences per batch\n",
    "    dataset = dataset.padded_batch(\n",
    "        batch_size=params['batch_size'],\n",
    "        padding_values=(params['mask_value'], params['mask_value']),\n",
    "        padded_shapes=([None, None], [None, None]),\n",
    "        drop_remainder=True\n",
    "    )\n",
    "\n",
    "    return dataset.repeat(), len(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee9676-4265-4ebc-a060-3ba499c74e6e",
   "metadata": {},
   "source": [
    "The data needs to be fed into the model in batches. Therefore, we need to specify in advance how many elements per batch our DKT will receive. Furthermore, all sequences should be of the same length in order to be fed into the model. Given that students have different number of opportunities across skills, we need to define a masking value for those entries that are introduced as a padding into the student's sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f10e7-d6f9-4a89-b996-9d4f62396062",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['batch_size'] = 32\n",
    "params['mask_value'] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fe3457-25d6-4219-b918-e40287049e2a",
   "metadata": {},
   "source": [
    "We are now ready to encode the data and split into a training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e3e61-d8c9-4dab-9a2b-0b0a372534c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtain indexes for necessary validation set\n",
    "train_val_index, val_index = next(create_iterator(X_train))\n",
    "# Split the training data into training and validation\n",
    "X_train_val, X_val = X_train.iloc[train_val_index], X_train.iloc[val_index]\n",
    "\n",
    "seq, features_depth, skill_depth = prepare_seq(data)\n",
    "seq_train = seq[X_train.user_id.unique()]\n",
    "seq_val = seq[X_train_val.user_id.unique()]\n",
    "seq_test = seq[X_test.user_id.unique()]\n",
    "\n",
    "tf_train, length = prepare_data(seq_train, params, features_depth, skill_depth)\n",
    "tf_val, val_length  = prepare_data(seq_val, params, features_depth, skill_depth)\n",
    "tf_test, test_length = prepare_data(seq_test, params, features_depth, skill_depth)\n",
    "\n",
    "params['train_size'] = int(length // params['batch_size'])\n",
    "params['val_size'] = int(val_length // params['batch_size'])\n",
    "params['test_size'] = int(test_length // params['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe316de-3995-4a84-b6ac-c531430feab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f2749-1c54-4921-bf82-1d4dcbfe974e",
   "metadata": {},
   "source": [
    "Next, we create and compile the model. To do so, we first define the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c006d5fa-6d45-4227-9511-ce5bf373e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['verbose'] = 1 # Verbose = {0,1,2}\n",
    "params['best_model_weights'] = 'weights/bestmodel' # File to save the model\n",
    "params['optimizer'] = 'adam' # Optimizer to use\n",
    "params['backbone_nn'] = tf.keras.layers.RNN # Backbone neural network\n",
    "params['recurrent_units'] = 16 # Number of RNN units\n",
    "params['epochs'] = 10  # Number of epochs to train\n",
    "params['dropout_rate'] = 0.3 # Dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ffa17-ca12-450b-8f8a-4957eaf1e91f",
   "metadata": {},
   "source": [
    "Considering that we padded the sequences such that all have the same length, we need to remove predictions on the time step associated with padding. We also need to mach each output with a specific skill.\n",
    "To this end, we implement a function calle get_target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169eac0-00c0-41ff-bd6a-bfdc2c1dd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(y_true, y_pred, mask_value=params['mask_value']):\n",
    "    \n",
    "    # Get skills and labels from y_true\n",
    "    mask = 1. - tf.cast(tf.equal(y_true, mask_value), y_true.dtype)\n",
    "    y_true = y_true * mask\n",
    "\n",
    "    skills, y_true = tf.split(y_true, num_or_size_splits=[-1, 1], axis=-1)\n",
    "\n",
    "    # Get predictions for each skill\n",
    "    y_pred = tf.reduce_sum(y_pred * skills, axis=-1, keepdims=True)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b1698-5006-4e46-b014-3d43b91db609",
   "metadata": {},
   "source": [
    "While training the model, we will monitor the following evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391fe1a6-cc62-4440-9147-e0a076ad1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUC(tf.keras.metrics.AUC):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true, pred = get_target(y_true, y_pred)\n",
    "        super(AUC, self).update_state(y_true=true, y_pred=pred, sample_weight=sample_weight)\n",
    "\n",
    "class RMSE(tf.keras.metrics.RootMeanSquaredError):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        true, pred = get_target(y_true, y_pred)\n",
    "        super(RMSE, self).update_state(y_true=true, y_pred=pred, sample_weight=sample_weight)\n",
    "        \n",
    "def CustomBinaryCrossEntropy(y_true, y_pred):    \n",
    "    y_true, y_pred = get_target(y_true, y_pred)\n",
    "    return tf.keras.losses.binary_crossentropy(y_true, y_pred)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b4b5a3a-3f3a-4729-a7f8-8196edbe85ea",
   "metadata": {},
   "source": [
    "We are now ready to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689b3b6-ca06-4c06-8901-50bbd0ec89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nb_features, nb_skills, params):\n",
    "    \n",
    "    # Create the model architecture\n",
    "    inputs = tf.keras.Input(shape=(None, nb_features), name='inputs')\n",
    "    x = tf.keras.layers.Masking(mask_value=params['mask_value'])(inputs)\n",
    "    x = tf.keras.layers.LSTM(params['recurrent_units'], return_sequences=True, dropout=params['dropout_rate'])(x)\n",
    "    dense = tf.keras.layers.Dense(nb_skills, activation='sigmoid')\n",
    "    outputs = tf.keras.layers.TimeDistributed(dense, name='outputs')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name='DKT')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=CustomBinaryCrossEntropy, \n",
    "                  optimizer=params['optimizer'], \n",
    "                  metrics=[AUC(), RMSE()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(features_depth, skill_depth, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f274fd4-b346-4d3f-ad8b-4e9ce6da7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c67834-af65-4db0-b5a3-e918da3e2af6",
   "metadata": {},
   "source": [
    "### Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e74c02-90df-4c44-9b88-c0287200cf57",
   "metadata": {},
   "source": [
    "Finally, we fit the model on the training data and evaluate it on the test data.\n",
    "We are using a callback for the model, i.e. we store the best model (on the validation set) and then use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e316425-3d56-469e-a3d3-0c100ae08fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_callback = tf.keras.callbacks.ModelCheckpoint(params['best_model_weights'], save_best_only=True, save_weights_only=True)\n",
    "history = model.fit(tf_train, epochs=params['epochs'], steps_per_epoch=params['train_size']-1, \n",
    "                    validation_data=tf_val,  validation_steps = params['val_size'], \n",
    "                    callbacks=[ckp_callback], verbose=params['verbose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70c6c2-e7e1-499b-bdff-b455aadf86a0",
   "metadata": {},
   "source": [
    "We evaluate on the test data set and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b63e31-baec-4b66-83d2-1b50471950f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(params['best_model_weights'])\n",
    "metrics_dkt_small = model.evaluate(tf_test, verbose=params['verbose'], steps = params['test_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470703c-ac7a-4886-9647-972cb43b9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy, AUC, RMSE\n",
    "metrics_dkt_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea8507-82fc-4a0a-afd8-cf0f3b88f409",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BKT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c717f-5cab-48c6-b4a3-495154b5cf24",
   "metadata": {},
   "source": [
    "We first also fit a BKT model to this data set using the same train/test split as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044fa2b-0958-41ff-92cc-cc5a7bc4c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame()\n",
    "\n",
    "# Train a BKT model for each skill\n",
    "for skill in skills_subset:\n",
    "    print(\"--{}--\".format(skill))\n",
    "    X_train_skill = X_train[X_train['skill_name'] == skill]\n",
    "    X_test_skill = X_test[X_test['skill_name'] == skill]\n",
    "    # Initialize and fit the model\n",
    "    model = Model(seed=0)\n",
    "    %time model.fit(data=X_train_skill) \n",
    "    preds = model.predict(data=X_test_skill) [['user_id', 'order_id', 'skill_name', 'correct', 'prev_attempts',\n",
    "       'before_correct_num', 'before_wrong_num', 'afm_predictions', 'pfa_predictions', 'correct_predictions']]\n",
    "    df_preds = df_preds.append(preds)\n",
    "\n",
    "X_test = df_preds\n",
    "X_test.columns = ['user_id', 'order_id', 'skill_name', 'correct', 'prev_attempts',\n",
    "       'before_correct_num', 'before_wrong_num', 'afm_predictions', 'pfa_predictions', 'bkt_predictions']\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a1b20-ff3b-4c43-8365-59e7c9cb4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(DATA_DIR + 'x_test_08.csv.gz', compression = 'gzip', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d43b8-0993-4a73-9cfe-7038ca4c165a",
   "metadata": {},
   "source": [
    "# Your Turn 1 - Model Comparison on Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49357c01-fcaa-4287-ab57-3a62bb9a5aed",
   "metadata": {},
   "source": [
    "Up to now, we have compared model performance on a subset of the data. Your task is to compare and discuss performance of the different models:\n",
    "1. Visualize the overall RMSE and AUC of the four models (AFM, PFA, BKT, DKT) such that the metrics can be easily compared.\n",
    "2. Interpret your results and discuss your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe40f4-a87c-4e3c-9d17-374237026a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lab-08',\n",
    "    'session_owner': 'mlbd',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e314a549-c21c-4ed5-8be0-672aa147b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it is taking too long to run, you may load our X_test to compute the RMSE and AUC\n",
    "X_test = pd.read_csv('x_test_08.csv.gz', compression = 'gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe56c0e-3441-4062-bc3f-4a3da03d03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize plots\n",
    "\n",
    "send(plt, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55380e4c-0241-4516-8ae7-dd934abb20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretation = \"\"\"\n",
    "Write your interpretation here\n",
    "\"\"\"\n",
    "\n",
    "send(interpretation, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ca99dc-50da-4a18-adc8-63417a4a136c",
   "metadata": {},
   "source": [
    "# Your Turn 2 - Model Comparison on Full Data Set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8733651-3af5-4ee8-9d90-473c251da1ef",
   "metadata": {},
   "source": [
    "Finally, we compare predictive performance of the models on the full data set. We only compare BKT (the previously best model) and DKT. Below you find the overall RMSE and AUC on of BKT and DKT on the full data set:\n",
    "1. Which model is doing better? Discuss your observations.\n",
    "2. Are the results different from the results on the subset of the data. If yes, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce00fd-d092-4112-812b-f150eae92c3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rmse_bkt = ...\n",
    "rmse_dkt = ...\n",
    "rmse = [rmse_bkt, rmse_dkt]\n",
    "models = ['BKT', 'DKT']\n",
    "\n",
    "plt.bar(models, rmse)\n",
    "plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1449ec-f3e4-40e7-86ea-39d75ee1b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_bkt = ...\n",
    "auc_dkt = ...\n",
    "auc = [rmse_bkt, rmse_dkt]\n",
    "models = ['BKT', 'DKT']\n",
    "\n",
    "plt.bar(models, auc)\n",
    "plt.ylabel('AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c60ab3-1c93-4ace-af63-3ff23b548481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model is doing a better? Discuss your observations.\n",
    "\n",
    "interpretation = \"\"\"\n",
    "Write your interpretation here\n",
    "\"\"\"\n",
    "\n",
    "send(interpretation, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f796da1-0a3a-405b-8b9f-a3afe872a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the results different from the results on the subset of the data. If yes, why?\n",
    "\n",
    "interpretation = \"\"\"\n",
    "Write your interpretation here\n",
    "\"\"\"\n",
    "\n",
    "send(interpretation, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
