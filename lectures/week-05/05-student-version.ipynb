{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891ad0db-af6a-4311-8f98-865c5197682a",
   "metadata": {},
   "source": [
    "# Lecture 5 - Student Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d46922-ee6e-4a8c-bddf-8a0b893a9ffe",
   "metadata": {},
   "source": [
    "We first load and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad19540-3541-4151-9bf4-f1987ed2048e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, auc\n",
    "from sklearn.utils import resample\n",
    "\n",
    "DATA_DIR = \"./../../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd61b5d-f273-4616-aa44-c0874a579baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the aggregated student data frame.\n",
    "# This data is from an EPFL Linear Algebra flipped classroom. df_lq is aggregated features for the last week of student performance.\n",
    "# ts represents the students' time series features.\n",
    "\n",
    "df_lq = pd.read_csv('{}/aggregated_extended_fc.csv'.format(DATA_DIR))\n",
    "ts = pd.read_csv('{}/time_series_extended_fc.csv'.format(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72168118-0033-47c4-ae99-2ba3b6891267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inactive_students(df, ts):\n",
    "    \"\"\"\n",
    "    Filter the students (removing the ones that are inactive) to proceed with analysis on students who have participated during the entire class.\n",
    "    Inputs: df, ts\n",
    "    Outputs: filtered df, ts\n",
    "    \"\"\"\n",
    "    # Fill all NaNs with strings to make them easier to process\n",
    "    df = df.fillna('NaN')\n",
    "    \n",
    "    # Find all users weeks with 0 clicks on weekends and 0 clicks on weekdays during the first weeks of the semester\n",
    "    df_first = ts[ts.week < 5]\n",
    "    rows = np.where(np.logical_and(df_first.ch_total_clicks_weekend==0, df_first.ch_total_clicks_weekday==0).to_numpy())[0]\n",
    "    df_zero = df_first.iloc[rows, :]\n",
    "    dropusers = np.unique(df_zero.user)\n",
    "\n",
    "    # Drop users with no activity\n",
    "    ts = ts[~ts.user.isin(dropusers)]\n",
    "    df = df[~df.user.isin(dropusers)]\n",
    "    return df, ts\n",
    "\n",
    "df_lq, ts = remove_inactive_students(df_lq, ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b2539-bcfc-40df-83d1-9eff25270fec",
   "metadata": {},
   "source": [
    "The `compute_scores` function computes the performance of classifiers with accuracy + AUC. We will use this evaluation function for all our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b78680-efbe-4a07-9213-7c8522698a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(clf, X_train, y_train, X_test, y_test, roundnum=3, report=False):\n",
    "    \"\"\"\n",
    "    Train clf (binary classification) model on X_train and y_train, predict on X_test. Evaluate predictions against ground truth y_test.\n",
    "    Inputs: clf, training set (X_train, y_train), test set (X_test, y_test)\n",
    "    Inputs (optional): roundnum (number of digits for rounding metrics), report (print scores)\n",
    "    Outputs: accuracy, AUC\n",
    "    \"\"\"\n",
    "    # Fit the clf predictor (passed in as an argument)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate roc AUC score\n",
    "    AUC = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    # Print classification results\n",
    "    if report:\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return round(accuracy, roundnum), round(AUC, roundnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ca4d9-f07f-4246-bb78-ad1fb3835d51",
   "metadata": {},
   "source": [
    "We compute the pass/fail label of the students in the dataframe to use for the experiments. We will use the aggregated dataframe (df_lq) for all our experiments. If students have a grade higher than or equal to 4, they have passed the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593c81c9-5d4d-4ddc-8b9b-6b3def76169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lq['passed'] = (df_lq.grade >= 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd443ce2-e939-40fe-8870-1c4f87108265",
   "metadata": {},
   "source": [
    "We are interested in model selection and assessment. We will use a random forest model for all our evaluations. For our evaluations, we will investigate behavioral features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de2d363-8d4f-4719-ae67-dfff6dd95f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ch_num_sessions', 'ch_time_in_prob_sum', 'ch_time_in_video_sum', 'ch_ratio_clicks_weekend_day', 'ch_total_clicks_weekend', 'ch_total_clicks_weekday', 'ch_time_sessions_mean', 'ch_time_sessions_std', 'bo_delay_lecture', 'bo_reg_peak_dayhour', 'bo_reg_periodicity_m1', 'ma_competency_strength', 'ma_competency_anti', 'ma_content_anti', 'ma_student_shape', 'ma_student_speed', 'mu_speed_playback_mean', 'mu_frequency_action_relative_video_pause', 'wa_num_subs', 'wa_num_subs_correct', 'wa_num_subs_avg', 'wa_num_subs_perc_correct', 'la_pause_dur_mean', 'la_seek_len_std', 'la_pause_dur_std', 'la_time_speeding_up_mean', 'la_time_speeding_up_std', 'la_weekly_prop_watched_mean', 'la_weekly_prop_interrupted_mean', 'la_weekly_prop_interrupted_std', 'la_weekly_prop_replayed_mean', 'la_weekly_prop_replayed_std', 'la_frequency_action_video_play']\n"
     ]
    }
   ],
   "source": [
    "# Filter out demographic features\n",
    "features = [x for x in df_lq.columns if x not in ['user', 'week', 'grade', 'gender', 'category', 'year', 'passed']]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561753df-2e54-45fe-baac-65c867a00019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep behavioral features in X.\n",
    "X = df_lq[features]\n",
    "\n",
    "# Our binary indicator variable is based on our evaluation criteria: pass/fail.\n",
    "y = df_lq['passed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aab671-cede-4817-a54c-21cbaaafd931",
   "metadata": {},
   "source": [
    "## Your Turn 1: Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc04c79-7cdc-4f81-b361-ef309004c8b3",
   "metadata": {},
   "source": [
    "In a first experiment, we are interested in assessing the generalizability of the trained model on to new data. We use two different methods to do so: a train-test split and a cross validation.\n",
    "Run the two methods and assess their accuracy/AUC:\n",
    "- What can you observe?\n",
    "- Where do the differences come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72257d09",
   "metadata": {},
   "source": [
    "##### Train-Test Split\n",
    "We split the data in a train-test split (stratified by the outcome variable) and obtain the accuracy and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24643627-f9ed-4d43-b6f7-b454e4f28629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train-test split is 80:20 (as shown by the 0.2 test_size argument). \n",
    "# We choose a random_state to replicate the results in the same split every time we run this notebook.\n",
    "# The stratify argument ensures a proportionate number of passes/fails are in the training set and the test set.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b14647-55de-41e7-850e-b708564c7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize a RandomForestClassifier to make our model predictions.\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a1b3e51-6eae-4e92-b45c-a64903a03aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-test setting: 0.723\n",
      "AUC for train-test setting: 0.723\n"
     ]
    }
   ],
   "source": [
    "# We can use our compute_scores function to evaluate the results of our train-test split classifier.\n",
    "\n",
    "accuracy, AUC = compute_scores(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(f'Accuracy for train-test setting: {accuracy}')\n",
    "print(f'AUC for train-test setting: {AUC}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a332370-626f-4c99-a8ef-2d6d0973ed9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Cross Validation\n",
    "We use a 10-fold cross validation to obtain accuracy and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41970544-d7c1-4008-b5e7-02de9a625683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new Random Forest predictor for our cross-validation comparison.\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f55e37-caab-4d85-80d8-b93868f04fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy with cross-validation: 0.667\n",
      "Mean AUC with cross-validation: 0.660\n"
     ]
    }
   ],
   "source": [
    "# With the cross_validate function, the SciKit Learn library automatically uses stratification across folds with the \"cv\" argument. \n",
    "# In the background, it's using the StratifiedKFold function with 10 folds.\n",
    "# We pass in our desired metrics (\"accuracy\", \"roc_auc\") for evaluation in the \"scoring\" argument.\n",
    "\n",
    "scores = cross_validate(clf, X, y, cv=3, scoring=['accuracy', 'roc_auc'])\n",
    "\n",
    "print(f'Mean accuracy with cross-validation: {scores[\"test_accuracy\"].mean():.3f}')\n",
    "print(f'Mean AUC with cross-validation: {scores[\"test_roc_auc\"].mean():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64008dc2",
   "metadata": {},
   "source": [
    "### Your solution 1\n",
    "Write your answers in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8733e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your name:  Paola\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "exec(requests.get(\"https://courdier.pythonanywhere.com/get-send-code\").content)\n",
    "\n",
    "npt_config = {\n",
    "    'session_name': 'lecture-05',\n",
    "    'session_owner': 'mlbd',\n",
    "    'sender_name': input(\"Your name: \"),\n",
    "}\n",
    "\n",
    "# YOUR TURN: what differences can you observe in the metrics (accuracy, AUC) between train-test and cross validation? Where do these differences come from?\n",
    "\n",
    "### Share the answer with us\n",
    "cv_tts = \"\"\n",
    "send(cv_tts, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff442a7-9bf9-4714-b56b-f35a2caaa43e",
   "metadata": {},
   "source": [
    "## Your Turn 2: Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83684f1-1beb-433e-8d1b-6763add6864d",
   "metadata": {},
   "source": [
    "Of course, when training ML models, we want to tune their hyperparameters in order to optimize the performance. In order to tune the hyperparameters of a model, we need to do further splits of our data set.  In the following, we present an incorrect example. Your task is to:\n",
    "- Explain why it is incorrect. \n",
    "- Describe how it could be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26bac26d-2e7c-4e74-9a65-ff6b082a15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute a grid search across the following parameter space\n",
    "parameters = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': np.arange(3, 7),\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4798f07b-a316-46a0-adb3-5adfd38ae4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['entropy', 'gini'],\n",
       "                         'max_depth': array([3, 4, 5, 6]),\n",
       "                         'min_samples_leaf': [1], 'min_samples_split': [2],\n",
       "                         'n_estimators': [20, 50, 100]},\n",
       "             refit='accuracy', scoring=['accuracy', 'roc_auc'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation to identify the best hyperparameters, selecting the ones with the highest accuracy\n",
    "clf = GridSearchCV(RandomForestClassifier(random_state=42), parameters, cv=10, scoring=['accuracy', 'roc_auc'], refit='accuracy')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "738d0830-b75e-4fe8-a47e-e002686e45a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b33fe1b-46ca-4cd7-8257-0e34a2146266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train-validation-test setting: 0.726\n",
      "AUC for train-validation-test setting: 0.707\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.cv_results_['mean_test_accuracy'][clf.best_index_]\n",
    "AUC = clf.cv_results_['mean_test_roc_auc'][clf.best_index_]\n",
    "\n",
    "print(f'Accuracy for train-validation-test setting: {accuracy:.3f}')\n",
    "print(f'AUC for train-validation-test setting: {AUC:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e2221",
   "metadata": {},
   "source": [
    "### Your Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69994d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN: Explain why it is incorrect. \n",
    "answer = \"\"\n",
    "send(answer, 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc8ac502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR TURN: Describe how it could be fixed.\n",
    "answer = \"\"\n",
    "send(answer, 3) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
